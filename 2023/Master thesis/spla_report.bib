@book{saturday_is_monday,
  author    = "Стругацкий, А.Н. and Стругацкий, Б.Н.",
  title     = "Понедельник начинается в субботу",
  address   = "М.",
  editor    = "Иванов",
  publisher = "Детская литература",
  year      = 1965,
  language  = "russian"
}
@book{book:fourier,
  title      = {Ряды и интеграл Фурье: Теория поля. Аналитические и специальные функции. Преобразование Лапласа},
  author     = {Кожевников, Н.И. and Краснощекова, Т.И. and Шишкин, Н.Е.},
  lccn       = {66051327},
  series     = {Избранные главы высшей математики для инженеров и студентов втузов. Задачи и упражнения},
  url        = {http://books.google.ru/books?id=xvXuAAAAMAAJ},
  year       = {1964},
  publisher  = {Наука},
  eprint     = {http://books.google.ru/books?id=xvXuAAAAMAAJ},
  eprinttype = {Google Books}
}
@online{wiki:lcd,
  author       = "Wikipedia",
  title        = "Наибольший общий делитель",
  howpublished = "Википедия, свободная энциклопедия",
  year         = 2012,
  url          = {http://goo.gl/1eEF3},
  urldate      = "08.04.2013",
  language     = "russian"
}

% Graph data model application
@inproceedings{article:querying_graph_databases,
    author = {Barcel\'{o} Baeza, Pablo},
    title = {Querying Graph Databases},
    year = {2013},
    isbn = {9781450320665},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2463664.2465216},
    doi = {10.1145/2463664.2465216},
    abstract = {Graph databases have gained renewed interest in the last years, due to its applications in areas such as the Semantic Web and Social Networks Analysis. We study the problem of querying graph databases, and, in particular, the expressiveness and complexity of evaluation for several general-purpose query languages, such as the regular path queries and its extensions with conjunctions and inverses. We distinguish between two semantics for these languages. The first one, based on simple paths, easily leads to intractability, while the second one, based on arbitrary paths, allows tractable evaluation for an expressive family of languages.We also study two recent extensions of these languages that have been motivated by modern applications of graph databases. The first one allows to treat paths as first-class citizens, while the second one permits to express queries that combine the topology of the graph with its underlying data.},
    booktitle = {Proceedings of the 32nd ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {175–188},
    numpages = {14},
    keywords = {query evaluation, conjunctive regular path queries, containment, graph databases, expressiveness},
    location = {New York, New York, USA},
    series = {PODS '13}
}

% Graph data model application (also cfpq on rdf example)
@article{article:cfpq_and_rdf_analysis,
    author    = {Xiaowang Zhang and
               Zhiyong Feng and
               Xin Wang and
               Guozheng Rao and
               Wenrui Wu},
    title     = {Context-Free Path Queries on {RDF} Graphs},
    journal   = {CoRR},
    volume    = {abs/1506.00743},
    year      = {2015},
    url       = {http://arxiv.org/abs/1506.00743},
    archivePrefix = {arXiv},
    eprint    = {1506.00743},
    timestamp = {Fri, 20 Mar 2020 11:46:30 +0100},
    biburl    = {https://dblp.org/rec/journals/corr/ZhangFWR15.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Graph data model application
@article{article:rna_prediction,
    author = {Anderson, James and Novák, Adám and Sükösd, Zsuzsanna and Golden, Michael and Arunapuram, Preeti and Edvardsson, Ingolfur and Hein, Jotun},
    year = {2013},
    month = {05},
    pages = {149},
    title = {Quantifying variances in comparative RNA secondary structure prediction},
    volume = {14},
    journal = {BMC bioinformatics},
    doi = {10.1186/1471-2105-14-149}
}

% Graph data model application
@article{article:dyck_cfl_code_analysis,
    author = {Zhang, Qirun and Lyu, Michael R. and Yuan, Hao and Su, Zhendong},
    title = {Fast Algorithms for Dyck-CFL-Reachability with Applications to Alias Analysis},
    year = {2013},
    issue_date = {June 2013},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {48},
    number = {6},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/2499370.2462159},
    doi = {10.1145/2499370.2462159},
    abstract = {The context-free language (CFL) reachability problem is a well-known fundamental formulation in program analysis. In practice, many program analyses, especially pointer analyses, adopt a restricted version of CFL-reachability, Dyck-CFL-reachability, and compute on edge-labeled bidirected graphs. Solving the all-pairs Dyck-CFL-reachability on such bidirected graphs is expensive. For a bidirected graph with n nodes and m edges, the traditional dynamic programming style algorithm exhibits a subcubic time complexity for the Dyck language with k kinds of parentheses. When the underlying graphs are restricted to bidirected trees, an algorithm with O(n log n log k) time complexity was proposed recently. This paper studies the Dyck-CFL-reachability problems on bidirected trees and graphs. In particular, it presents two fast algorithms with O(n) and O(n + m log m) time complexities on trees and graphs respectively. We have implemented and evaluated our algorithms on a state-of-the-art alias analysis for Java. Results on standard benchmarks show that our algorithms achieve orders of magnitude speedup and consume less memory.},
    journal = {SIGPLAN Not.},
    month = jun,
    pages = {435–446},
    numpages = {12},
    keywords = {alias analysis, dyck-cfl-reachability}
}

% Graph data model application
@article{article:facebook_large_scale,
    author = {Ching, Avery and Edunov, Sergey and Kabiljo, Maja and Logothetis, Dionysios and Muthukrishnan, Sambavi},
    title = {One Trillion Edges: Graph Processing at Facebook-Scale},
    year = {2015},  
    issue_date = {August 2015},
    publisher = {VLDB Endowment},
    volume = {8},
    number = {12},
    issn = {2150-8097},
    url = {https://doi.org/10.14778/2824032.2824077},
    doi = {10.14778/2824032.2824077},
    abstract = {Analyzing large graphs provides valuable insights for social networking and web companies in content ranking and recommendations. While numerous graph processing systems have been developed and evaluated on available benchmark graphs of up to 6.6B edges, they often face significant difficulties in scaling to much larger graphs. Industry graphs can be two orders of magnitude larger - hundreds of billions or up to one trillion edges. In addition to scalability challenges, real world applications often require much more complex graph processing workflows than previously evaluated. In this paper, we describe the usability, performance, and scalability improvements we made to Apache Giraph, an open-source graph processing system, in order to use it on Facebook-scale graphs of up to one trillion edges. We also describe several key extensions to the original Pregel model that make it possible to develop a broader range of production graph applications and workflows as well as improve code reuse. Finally, we report on real-world operations as well as performance characteristics of several large-scale production applications.},
    journal = {Proc. VLDB Endow.},
    month = {aug},
    pages = {1804–1815},
    numpages = {12}
}

% Graph databases overview
@inbook{inbook:databases_intro,
    author = {Abiteboul, Serge and Hull, Richard and Vianu, Victor},
    year = {1995},
    month = {01},
    pages = {},
    title = {Foundations of Databases},
    isbn = {0-201-53771-0}
}

% Cfpq example
@article{article:hellings_cfpq,
    author = {Hellings, Jelle},
    year = {2015},
    month = {02},
    pages = {},
    title = {Path Results for Context-free Grammar Queries on Graphs}
}

% Cfpq (relational semantic introduction)
@inproceedings{article:hellings2014conjunctive,
  doi = {10.5441/002/ICDT.2014.15},
  url = {https://openproceedings.org/ICDT/2014/paper_34.pdf},
  author = {Hellings,  Jelle},
  keywords = {Database Theory,  Database Technology},
  language = {eng},
  title = {Conjunctive Context-Free Path Queries},
  publisher = {OpenProceedings.org},
  year = {2014}
}

% Cfpq example
@inproceedings{inproceedings:matrix_cfpq,
    author = {Azimov, Rustam and Grigorev, Semyon},
    year = {2018},
    month = {06},
    pages = {1-10},
    title = {Context-free path querying by matrix multiplication},
    doi = {10.1145/3210259.3210264}
}

% Cfpq example
@inbook{inbook:kronecker_cfpq_adbis,
    author = {Orachev, Egor and Epelbaum, Ilya and Azimov, Rustam and Grigorev, Semyon},
    year = {2020},
    month = {08},
    pages = {49-59},
    title = {Context-Free Path Querying by Kronecker Product},
    isbn = {978-3-030-54831-5},
    doi = {10.1007/978-3-030-54832-2_6}
}

% Cfpq example
@article{article:cfpq_go_for_rdf,
    author = {Medeiros, Ciro and Musicante, Martin and Costa, Umberto},
    year = {2020},
    month = {04},
    pages = {},
    title = {An Algorithm for Context-Free Path Queries over Graph Databases}
}

% 2019 matrix-algo evaluatoion for dense CUDA matrices
@inproceedings{inproceedings:cfpq_matrix_evaluation,
    author = {Mishin, Nikita and Sokolov, Iaroslav and Spirin, Egor and Kutuev, Vladimir and Nemchinov, Egor and Gorbatyuk, Sergey and Grigorev, Semyon},
    year = {2019},
    month = {06},
    pages = {1-5},
    title = {Evaluation of the Context-Free Path Querying Algorithm Based on Matrix Multiplication},
    doi = {10.1145/3327964.3328503}
}

% SpGEMM for NVIDIA CUDA
@inproceedings{inproceedings:spgemm_mem_saving_for_nvidia,
    author = {Nagasaka, Yusuke and Nukada, Akira and Matsuoka, Satoshi},
    year = {2017},
    month = {08},
    pages = {101-110},
    title = {High-Performance and Memory-Saving Sparse General Matrix-Matrix Multiplication for NVIDIA Pascal GPU},
    doi = {10.1109/ICPP.2017.19}
}

% Most recent single source matrix-algo implementation with CUDA support
@inproceedings{inproceedings:cfqp_matrix_with_single_source,
    author = {Terekhov, Arseniy and Khoroshev, Artyom and Azimov, Rustam and Grigorev, Semyon},
    year = {2020},
    month = {06},
    pages = {1-12},
    title = {Context-Free Path Querying with Single-Path Semantics by Matrix Multiplication},
    doi = {10.1145/3398682.3399163}
}

% Recursive state machines formalizm introduction
@article{article:recursive_state_machines,
    author = {Alur, Rajeev and Benedikt, Michael and Etessami, Kousha and Godefroid, Patrice and Reps, Thomas and Yannakakis, Mihalis},
    title = {Analysis of Recursive State Machines},
    year = {2005},
    issue_date = {July 2005},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {27},
    number = {4},
    issn = {0164-0925},
    url = {https://doi.org/10.1145/1075382.1075387},
    doi = {10.1145/1075382.1075387},
    abstract = {Recursive state machines (RSMs) enhance the power of ordinary state machines by allowing vertices to correspond either to ordinary states or to potentially recursive invocations of other state machines. RSMs can model the control flow in sequential imperative programs containing recursive procedure calls. They can be viewed as a visual notation extending Statecharts-like hierarchical state machines, where concurrency is disallowed but recursion is allowed. They are also related to various models of pushdown systems studied in the verification and program analysis communities.After introducing RSMs and comparing their expressiveness with other models, we focus on whether verification can be efficiently performed for RSMs. Our first goal is to examine the verification of linear time properties of RSMs. We begin this study by dealing with two key components for algorithmic analysis and model checking, namely, reachability (Is a target state reachable from initial states?) and cycle detection (Is there a reachable cycle containing an accepting state?). We show that both these problems can be solved in time O(nθ2) and space O(nθ), where n is the size of the recursive machine and θ is the maximum, over all component state machines, of the minimum of the number of entries and the number of exits of each component. From this, we easily derive algorithms for linear time temporal logic model checking with the same complexity in the model. We then turn to properties in the branching time logic CTL*, and again demonstrate a bound linear in the size of the state machine, but only for the case of RSMs with a single exit node.},
    journal = {ACM Trans. Program. Lang. Syst.},
    month = jul,
    pages = {786–818},
    numpages = {33},
    keywords = {pushdown automata, Software verification, recursive state machines, temporal logic, model checking, program analysis, context-free languages}
}

% Hopcroft formal languages theory
@book{book:automata_theory,
    author = {Hopcroft, John E. and Motwani, Rajeev and Ullman, Jeffrey D.},
    title = {Introduction to Automata Theory, Languages, and Computation (3rd Edition)},
    year = {2006},
    isbn = {0321455363},
    publisher = {Addison-Wesley Longman Publishing Co., Inc.},
    address = {USA}
}

% Cfpq implementations becnch for Neo4j database
@inproceedings{article:kuijpers_cfpq_exp_compare,
    author = {Kuijpers, Jochem and Fletcher, George and Yakovets, Nikolay and Lindaaker, Tobias},
    title = {An Experimental Study of Context-Free Path Query Evaluation Methods},
    booktitle = {Proceedings of the 31st International Conference on Scientific and Statistical Database Management},
    series = {SSDBM '19},
    year = {2019},
    isbn = {978-1-4503-6216-0},
    location = {Santa Cruz, CA, USA},
    pages = {121--132},
    numpages = {12},
    url = {http://doi.acm.org/10.1145/3335783.3335791},
    doi = {10.1145/3335783.3335791},
    acmid = {3335791},
    publisher = {ACM},
    address = {New York, NY, USA},
} 

% First introduction of cfpq problem
@inproceedings{inproceedings:yannakakis_cfpq_problem,
    author = {Yannakakis, Mihalis},
    title = {Graph-Theoretic Methods in Database Theory},
    year = {1990},
    isbn = {0897913523},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/298514.298576},
    doi = {10.1145/298514.298576},
    booktitle = {Proceedings of the Ninth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
    pages = {230–242},
    numpages = {13},
    location = {Nashville, Tennessee, USA},
    series = {PODS '90}
}

% Cfpq algo based on LR analysis (from 2019 Kujipers comp)
@inbook{inbook:santos_cfpq_lr_analysis,
    author = {Santos, Fred and Costa, Umberto and Musicante, Martin},
    year = {2018},
    month = {01},
    pages = {225-233},
    title = {A Bottom-Up Algorithm for Answering Context-Free Path Queries in Graph Databases},
    isbn = {978-3-319-91661-3},
    doi = {10.1007/978-3-319-91662-0_17}
}

% Simple rpq arrival algo for graph networks
@inproceedings{10.1145/3299869.3319882,
    author = {Wadhwa, Sarisht and Prasad, Anagh and Ranu, Sayan and Bagchi, Amitabha and Bedathur, Srikanta},
    title = {Efficiently Answering Regular Simple Path Queries on Large Labeled Networks},
    year = {2019},
    isbn = {9781450356435},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3299869.3319882},
    doi = {10.1145/3299869.3319882},
    abstract = {A fundamental query in labeled graphs is to determine if there exists a path between a given source and target vertices, such that the path satisfies a given label constraint. One of the powerful forms of specifying label constraints is through regular expressions, and the resulting problem of reachability queries under regular simple paths (RSP) form the core of many practical graph query languages such as SPARQL from W3C, Cypher of Neo4J, Oracle's PGQL and LDBC's G-CORE. Despite its importance, since it is known that answering RSP queries is NP-Hard, there are no scalable and practical solutions for answering reachability with full-range of regular expressions as constraints. In this paper, we circumvent this computational bottleneck by designing a random-walk based sampling algorithm called ARRIVAL, which is backed by theoretical guarantees on its expected quality. Extensive experiments on billion-sized real graph datasets with thousands of labels show that ARRIVAL to be 100 times faster than baseline strategies with an average accuracy of 95%.},
    booktitle = {Proceedings of the 2019 International Conference on Management of Data},
    pages = {1463–1480},
    numpages = {18},
    keywords = {random walks, regular path query, knowledge graphs, regular expression, reachability query},
    location = {Amsterdam, Netherlands},
    series = {SIGMOD '19}
}

% RDF RPQ for Glushkov automata
@article{article:provenance_aware_rpq,
    author = {Wang, Xin and Wang, Simiao and Xin, Yueqi and Yang, Yajun and Li, Jianxin and Wang, Xiaofei},
    year = {2020},
    month = {05},
    pages = {},
    title = {Distributed Pregel-based provenance-aware regular path query processing on RDF knowledge graphs},
    volume = {23},
    journal = {World Wide Web},
    doi = {10.1007/s11280-019-00739-0}
}

% Analogs Gunrock framework
@article{article:gunrock,
   title={Gunrock},
   url={http://dx.doi.org/10.1145/2851141.2851145},
   DOI={10.1145/2851141.2851145},
   journal={Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
   publisher={ACM},
   author={Wang, Yangzihao and Davidson, Andrew and Pan, Yuechao and Wu, Yuduo and Riffel, Andy and Owens, John D.},
   year={2016},
   month={Feb}
}

% Analogs Ligra
@article{article:ligra,
    author = {Shun, Julian and Blelloch, Guy E.},
    title = {Ligra: A Lightweight Graph Processing Framework for Shared Memory},
    year = {2013},
    issue_date = {August 2013},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {48},
    number = {8},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/2517327.2442530},
    doi = {10.1145/2517327.2442530},
    abstract = {There has been significant recent interest in parallel frameworks for processing graphs due to their applicability in studying social networks, the Web graph, networks in biology, and unstructured meshes in scientific simulation. Due to the desire to process large graphs, these systems have emphasized the ability to run on distributed memory machines. Today, however, a single multicore server can support more than a terabyte of memory, which can fit graphs with tens or even hundreds of billions of edges. Furthermore, for graph algorithms, shared-memory multicores are generally significantly more efficient on a per core, per dollar, and per joule basis than distributed memory systems, and shared-memory algorithms tend to be simpler than their distributed counterparts.In this paper, we present a lightweight graph processing framework that is specific for shared-memory parallel/multicore machines, which makes graph traversal algorithms easy to write. The framework has two very simple routines, one for mapping over edges and one for mapping over vertices. Our routines can be applied to any subset of the vertices, which makes the framework useful for many graph traversal algorithms that operate on subsets of the vertices. Based on recent ideas used in a very fast algorithm for breadth-first search (BFS), our routines automatically adapt to the density of vertex sets. We implement several algorithms in this framework, including BFS, graph radii estimation, graph connectivity, betweenness centrality, PageRank and single-source shortest paths. Our algorithms expressed using this framework are very simple and concise, and perform almost as well as highly optimized code. Furthermore, they get good speedups on a 40-core machine and are significantly more efficient than previously reported results using graph frameworks on machines with many more cores.},
    journal = {SIGPLAN Not.},
    month = {feb},
    pages = {135–146},
    numpages = {12},
    keywords = {parallel programming, graph algorithms, shared memory}
}

% SuiteSparse for solving graph problems
@article{article:suite_sparse_for_graph_problems,
    author = {Davis, Timothy A.},
    title = {Algorithm 1000: SuiteSparse:GraphBLAS: Graph Algorithms in the Language of Sparse Linear Algebra},
    year = {2019},
    issue_date = {December 2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {45},
    number = {4},
    issn = {0098-3500},
    url = {https://doi.org/10.1145/3322125},
    doi = {10.1145/3322125},
    abstract = {SuiteSparse:GraphBLAS is a full implementation of the GraphBLAS standard, which defines a set of sparse matrix operations on an extended algebra of semirings using an almost unlimited variety of operators and types. When applied to sparse adjacency matrices, these algebraic operations are equivalent to computations on graphs. GraphBLAS provides a powerful and expressive framework for creating graph algorithms based on the elegant mathematics of sparse matrix operations on a semiring. An overview of the GraphBLAS specification is given, followed by a description of the key features and performance of its implementation in the SuiteSparse:GraphBLAS package.},
    journal = {ACM Trans. Math. Softw.},
    month = dec,
    articleno = {44},
    numpages = {25},
    keywords = {Graph algorithms, GraphBLAS, sparse matrices}
}

% Ref pygraphblas
@MISC{net:pygraphblas,
    title = {pygraphblas: a Python wrapper around the GraphBLAS API},
    url = {https://github.com/Graphegon/pygraphblas},
    urldate = "28.12.2022",
    language = "english"
}

% Ref pygraphblas
@MISC{net:galatic,
    title = {GALATIC: GPU Accelerated Sparse Matrix Multiplication over Arbitrary Semirings},
    url = {https://github.com/richardlett/GALATIC},
    urldate = "28.12.2022",
    language = "english"
}

% Analogs (cuBool and SPbLA)
@INPROCEEDINGS{
    article:spbla,  
    author={Orachev, Egor and Karpenko, Maria and Khoroshev, Artem and Grigorev, Semyon}, 
    booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
    title={SPbLA: The Library of GPGPU-Powered Sparse Boolean Linear Algebra Operations},  
    year={2021}, 
    volume={}, 
    number={}, 
    pages={272-275}, 
    doi={10.1109/IPDPSW52791.2021.00049}
}

% cuSPARSE reference
@MISC{net:cusparse_docs,
  title = {Sparse  matrix  library  (in  Cuda)},
  url = {https://docs.nvidia.com/cuda/cusparse/},
  urldate      = "16.04.2021",
  language     = "english"
}

% bhSPARSE
@article{article:bhsparse,
 author = {Liu, Weifeng and Vinter, Brian},
 title = {A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and Heterogeneous Processors},
 year = {2015},
 issue_date = {November 2015},
 publisher = {Academic Press, Inc.},
 address = {USA},
 volume = {85},
 number = {C},
 issn = {0743-7315},
 url = {https://doi.org/10.1016/j.jpdc.2015.06.010},
 doi = {10.1016/j.jpdc.2015.06.010},
 abstract = {General sparse matrix-matrix multiplication (SpGEMM) is a fundamental building block for numerous applications such as algebraic multigrid method (AMG), breadth first search and shortest path problem. Compared to other sparse BLAS routines, an efficient parallel SpGEMM implementation has to handle extra irregularity from three aspects: (1) the number of nonzero entries in the resulting sparse matrix is unknown in advance, (2) very expensive parallel insert operations at random positions in the resulting sparse matrix dominate the execution time, and (3) load balancing must account for sparse data in both input matrices.In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU heterogeneous processors. This framework particularly focuses on the above three problems. Memory pre-allocation for the resulting matrix is organized by a hybrid method that saves a large amount of global memory space and efficiently utilizes the very limited on-chip scratchpad memory. Parallel insert operations of the nonzero entries are implemented through the GPU merge path algorithm that is experimentally found to be the fastest GPU merge approach. Load balancing builds on the number of necessary arithmetic operations on the nonzero entries and is guaranteed in all stages.Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach delivers excellent absolute performance and relative speedups on various benchmarks multiplying matrices with diverse sparsity structures. Furthermore, on heterogeneous processors, our SpGEMM approach achieves higher throughput by using re-allocatable shared virtual memory. We design a framework for SpGEMM on modern manycore processors using the CSR format.We present a hybrid method for pre-allocating the resulting sparse matrix.We propose an efficient parallel insert method for long rows of the resulting matrix.We develop a heuristic-based load balancing strategy.Our approach significantly outperforms other known CPU and GPU SpGEMM methods.},
 journal = {J. Parallel Distrib. Comput.},
 month = nov,
 pages = {47--61},
 numpages = {15},
 keywords = {Linear algebra, Sparse matrix, Sparse matrix-matrix multiplication, Heterogeneous processor, GPU, Merging, Parallel algorithm}
}

% Graphblast
@article{yang2019graphblast,
  title = {{GraphBLAST}: A High-Performance Linear Algebra-based Graph Framework on the {GPU}},
  author = {Carl Yang and Ayd{\i}n Bulu{\c{c}} and John D. Owens},
  year = {2019},
  journal = {arXiv preprint},
  arxiv = {https://arxiv.org/abs/1908.01407}
}

% Cusplibrary project
@MISC{net:cusplibrary,
  author = "Steven Dalton and Nathan Bell and Luke Olson and Michael Garland",
  title = "Cusp: Generic Parallel Algorithms for Sparse Matrix and Graph Computations",
  year = "2014",
  url = "http://cusplibrary.github.io/",
  note = "Version 0.5.0"
}

% clSPARSE project
@inproceedings{article:clsparse,
author = {Greathouse, Joseph L. and Knox, Kent and Po\l{}a, Jakub and Varaganti, Kiran and Daga, Mayank},
title = {ClSPARSE: A Vendor-Optimized Open-Source Sparse BLAS Library},
year = {2016},
isbn = {9781450343381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2909437.2909442},
doi = {10.1145/2909437.2909442},
abstract = {Sparse linear algebra is a cornerstone of modern computational science. These algorithms ignore the zero-valued entries found in many domains in order to work on much larger problems at much faster rates than dense algorithms. Nonetheless, optimizing these algorithms is not straightforward. Highly optimized algorithms for multiplying a sparse matrix by a dense vector, for instance, are the subject of a vast corpus of research and can be hundreds of times longer than na\"{\i}ve implementations. Optimized sparse linear algebra libraries are thus needed so that users can build applications without enormous effort.Hardware vendors release proprietary libraries that are highly optimized for their devices, but they limit interoperability and promote vendor lock-in. Open libraries often work across multiple devices and can quickly take advantage of new innovations, but they may not reach peak performance. The goal of this work is to provide a sparse linear algebra library that offers both of these advantages.We thus describe clSPARSE, a permissively licensed open-source sparse linear algebra library that offers state-of-the-art optimized algorithms implemented in OpenCL™. We test clSPARSE on GPUs from AMD and Nvidia and show performance benefits over both the proprietary cuSPARSE library and the open-source ViennaCL library.},
booktitle = {Proceedings of the 4th International Workshop on OpenCL},
articleno = {7},
numpages = {4},
keywords = {GPGPU, OpenCL, Sparse Linear Algebra, clSPARSE},
location = {Vienna, Austria},
series = {IWOCL '16}
}

% Cfpq Py Algo
@online{net:cfpq_py_algo,
    title      = "A collection of CFPQ algorithms implemented in PyGraphBLAS",
    howpublished = "Github",
    year       = 2020,
    url        = {https://github.com/JetBrains-Research/CFPQ_PyAlgo},
    urldate    = "16.12.2020",
    language   = "english"
} 

% Cfpq Data
@online{net:cfpq_data,
    title      = "Graphs and grammars for Context-Free Path Querying algorithms evaluation",
    howpublished = "Github",
    year       = 2021,
    url        = {https://github.com/JetBrains-Research/CFPQ_Data},
    urldate    = "11.03.2021",
    language   = "english"
} 
% Cuda toolkit reference
@online{net:cuda_toolkit_docs,
    author       = "NVIDIA",
    title        = "CUDA Toolkit Documentation",
    howpublished = "NVIDIA Developer Zone",
    year         = 2020,
    url          = {https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html},
    urldate      = "01.12.2020",
    language     = "english"
}

% Cuda toolkit reference
@online{net:cuda_thrust,
    author       = "NVIDIA",
    title        = "CUDA Thrust",
    howpublished = "NVIDIA Developer Zone",
    year         = 2020,
    url          = {https://docs.nvidia.com/cuda/thrust/index.html},
    urldate      = "16.12.2020",
    language     = "english"
}

% OpenCL API spec reference
@online{net:spec_opencl,
    title      = "OpenCL: Open Standard for Parallel Programming of Heterogeneous Systems",
    howpublished = "Khronos website",
    year       = 2020,
    url        = {https://www.khronos.org/opencl/},
    urldate    = "08.12.2020",
    language   = "english"
} 

% Suite-Sparse refernece
@online{net:suite_sparse,
    author       = "Dr. Timothy Alden, Davis",
    title        = "SuiteSparse: a suite of sparse matrix software",
    howpublished = "SuiteSparse website",
    year         = 2020,
    url          = {https://people.engr.tamu.edu/davis/suitesparse.html},
    urldate      = "08.12.2020",
    language     = "english"
}

% Vulkan API spec reference
@online{net:spec_vulkan,
    title      = "Vulkan 1.1 API Specification",
    author     = "Khronos Working Group The",
    howpublished = "Khronos Registry",
    year       = 2019,
    url        = {https://www.khronos.org/registry/vulkan/specs/1.1/html/vkspec.html},
    urldate    = "08.12.2020",
    language   = "english"
}     

% OpenGL API spec reference
@online{net:spec_opengl,
    title      = "OpenGL 4.4 Specification",
    author     = "Khronos Working Group The",
    howpublished = "Khronos Registry",
    year       = 2014,
    url        = {https://www.khronos.org/registry/OpenGL/specs/gl/glspec44.core.pdf},
    urldate    = "08.12.2020",
    language   = "english"
} 

% Direct3D API spec reference
@online{net:spec_direct3d,
    title      = "Direct3D 12 Graphics",
    howpublished = "Microsoft Online Documents",
    year       = 2018,
    url        = {https://docs.microsoft.com/ru-ru/windows/win32/direct3d12/direct3d-12-graphics?redirectedfrom=MSDN},
    urldate    = "08.12.2020",
    language   = "english"
} 

% Graphblas
@online{net:graphblas,
    title      = "GraphBLAS Graph Linear Algebra API",
    howpublished = "graphblas",
    year       = 2020,
    url        = {https://graphblas.github.io/},
    urldate    = "09.12.2020",
    language   = "english"
} 

% SPLA Project
@online{net:spla_project,
    title      = "spla: Generalized sparse linear algebgra framework for multi-GPU computations",
    howpublished = "Github",
    year       = 2021,
    url        = {https://github.com/JetBrains-Research/spla},
    urldata    = "28.12.2022",
    language   = "english"
} 

@INPROCEEDINGS{paper:redisgraph,
  author={P. {Cailliau} and T. {Davis} and V. {Gadepally} and J. {Kepner} and R. {Lipman} and J. {Lovitz} and K. {Ouaknine}},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={RedisGraph GraphBLAS Enabled Graph Database}, 
  year={2019},
  volume={},
  number={},
  pages={285-286},
  doi={10.1109/IPDPSW.2019.00054}
 }

% INtroduction (about graphblas)
@INPROCEEDINGS{paper:graphblas_foundations,
author={J. {Kepner} and P. {Aaltonen} and D. {Bader} and A. {Buluc} and F. {Franchetti} and J. {Gilbert} and D. {Hutchison} and M. {Kumar} and A. {Lumsdaine} and H. {Meyerhenke} and S. {McMillan} and C. {Yang} and J. D. {Owens} and M. {Zalewski} and T. {Mattson} and J. {Moreira}},
booktitle={2016 IEEE High Performance Extreme Computing Conference (HPEC)},
title={Mathematical foundations of the GraphBLAS},
year={2016},
volume={},
number={},
pages={1--9},
keywords={graph theory;mathematics computing;matrix algebra;programming environments;mathematical foundations;GraphBLAS standard;GraphBlas.org;matrix-based graph algorithms;matrix-based graph operations;programming environments;adjacency matrices;incidence matrices;matrix multiplication;matrix mathematics;Matrices;Sparse matrices;Finite element analysis;Standards;Additives},
doi={10.1109/HPEC.2016.7761646},
ISSN={},
month={Sep.},}


% Analogs (cuBool library)
@online{net:cubool_project,
    title      = "cuBool: sparse linera Boolean algebra for NVIDIA CUDA",
    howpublished = "Github",
    year       = 2020,
    url        = {https://github.com/JetBrains-Research/cuBool},
    urldata    = "28.12.2022",
    language   = "english"
} 

% Analogs (cuBool)
@online{net:cuBool,
  author = {Orachyov, Egor and Alimov, Pavel and Grigorev, Semyon},
  title = {cuBool: sparse Boolean linear algebra for Nvidia Cuda},
  year = 2020,
  url = {https://github.com/JetBrains-Research/cuBool},
  urldata = "28.12.2022",
  note = {Version 1.2.0}
}

% Analogs (cuBool)
@online{net:pycubool,
  author = {Orachyov, Egor and Alimov, Pavel and Grigorev, Semyon},
  title = {cuBool: sparse Boolean linear algebra for Nvidia Cuda},
  year = 2020,
  url = {https://pypi.org/project/pycubool/},
  urldata = "28.12.2022",
  note = {Version 1.2.0}
}

% Deps taskflow
@article{article:taskflow,
   title={Taskflow: A Lightweight Parallel and Heterogeneous Task Graph Computing System},
   volume={33},
   ISSN={2161-9883},
   url={http://dx.doi.org/10.1109/TPDS.2021.3104255},
   DOI={10.1109/tpds.2021.3104255},
   number={6},
   journal={IEEE Transactions on Parallel and Distributed Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Huang, Tsung-Wei and Lin, Dian-Lun and Lin, Chun-Xun and Lin, Yibo},
   year={2022},
   month={Jun},
   pages={1303–1320}
}

% Deps boost compute
@inproceedings{article:boost_compute,
    author = {Szuppe, Jakub},
    title = {Boost.Compute: A Parallel Computing Library for C++ Based on OpenCL},
    year = {2016},
    isbn = {9781450343381},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2909437.2909454},
    doi = {10.1145/2909437.2909454},
    abstract = {Boost.Compute is a powerful C++ header-only template library for parallel computing based on OpenCL. It has a layered architecture and acts both as a thin C++ wrapper over the OpenCL API and as a feature-rich interface to high-level constructs that resemble the functionality of the STL and is just as easy to use.Through its template-based design, Boost.Compute seeks to further provide flexible OpenCL support in C++ projects via meta-programming. Meta-programming is not available in standard C-based OpenCL, and OpenCL C++ kernel language is currently only provisional. SYCL is intended as a prospective C++ abstraction layer over OpenCL, but it is still under development and requires a special compiler. Bolt and Thrust are C++-based parallel-computing libraries, but they are tied to specific hardware vendors. Boost.Compute on the other hand is a vendor-neutral solution for GPUs and multi-core CPUs that is available now, and it works with any standard C++ compiler and on all OpenCL platforms.Boost.Compute has been accepted for integration with the official Boost C++ libraries. With this step, and considering the large number of Boost users, usage of Boost.Compute and visibility of OpenCL among C++ developers is likely to increase. This technical presentation is therefore intended as a comprehensive overview of Boost.Compute for current and prospective users of the library and covers the library's overall architecture, its low-level and high-level functionality and advanced topics such as custom functions, closures and lambda expressions. The presentation also describes how a custom template-based OpenCL library can be designed on top of Boost.Compute. Examples are included throughout the presentation to aid in a better understanding. Among others, I will demonstrate how advanced features of the library can lead to a simple and efficient C++-only solution for BLAS calculations. The architectural presentation of the library will be followed by a presentation of current performance results of the library and a comparison with competing solutions. I will conclude the presentation with insights that I gained during Google Summer of Code '15 and my overall experience in contributing to Boost.Compute, which I hope to be of interest to the wider developer community.},
    booktitle = {Proceedings of the 4th International Workshop on OpenCL},
    articleno = {15},
    numpages = {39},
    keywords = {Boost Compute, C++, Boost C++ Libraries, Parallel computing, OpenCL},
    location = {Vienna, Austria},
    series = {IWOCL '16}
}

% Sparse matrix data
@online{net:sp_matrix_data_florida,
    title       = "T. Davis. The SuiteSparse Matrix Collection (the University of Florida Sparse Matrix Collection)",
    year       = 2020,
    url        = {https://sparse.tamu.edu},
    urldate    = "09.03.2021",
    language   = "english"
}
    
% Alias analysis
@article{Zheng:2008:DAA:1328897.1328464,
 author = {Zheng, Xin and Rugina, Radu},
 title = {Demand-driven Alias Analysis for C},
 journal = {SIGPLAN Not.},
 issue_date = {January 2008},
 volume = {43},
 number = {1},
 month = jan,
 year = {2008},
 issn = {0362-1340},
 pages = {197--208},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1328897.1328464},
 doi = {10.1145/1328897.1328464},
 acmid = {1328464},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CFL reachability, alias analysis, demand-driven analysis, memory disambiguation, pointer analysis},
}

% Alias analysis grammar
@article{10.1145/3093336.3037744,
 author = {Wang, Kai and Hussain, Aftab and Zuo, Zhiqiang and Xu, Guoqing and Amiri Sani, Ardalan},
 title = {Graspan: A Single-Machine Disk-Based Graph System for Interprocedural Static Analyses of Large-Scale Systems Code},
 year = {2017},
 issue_date = {April 2017},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 volume = {52},
 number = {4},
 issn = {0362-1340},
 url = {https://doi.org/10.1145/3093336.3037744},
 doi = {10.1145/3093336.3037744},
 abstract = {There is more than a decade-long history of using static analysis to find bugs in systems such as Linux. Most of the existing static analyses developed for these systems are simple checkers that find bugs based on pattern matching. Despite the presence of many sophisticated interprocedural analyses, few of them have been employed to improve checkers for systems code due to their complex implementations and poor scalability. In this paper, we revisit the scalability problem of interprocedural static analysis from a "Big Data" perspective. That is, we turn sophisticated code analysis into Big Data analytics and leverage novel data processing techniques to solve this traditional programming language problem. We develop Graspan, a disk-based parallel graph system that uses an edge-pair centric computation model to compute dynamic transitive closures on very large program graphs.We implement context-sensitive pointer/alias and dataflow analyses on Graspan. An evaluation of these analyses on large codebases such as Linux shows that their Graspan implementations scale to millions of lines of code and are much simpler than their original implementations. Moreover, we show that these analyses can be used to augment the existing checkers; these augmented checkers uncovered 132 new NULL pointer bugs and 1308 unnecessary NULL tests in Linux 4.4.0-rc5, PostgreSQL 8.3.9, and Apache httpd 2.2.18.},
 journal = {SIGPLAN Not.},
 month = apr,
 pages = {389--404},
 numpages = {16},
 keywords = {disk-based systems, static analysis, graph processing}
}

% Graph analysis survey
@article{article:graph_landscape,
  doi = {10.1186/s40537-021-00443-9},
  url = {https://doi.org/10.1186/s40537-021-00443-9},
  year = {2021},
  month = apr,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {8},
  number = {1},
  author = {Miguel E. Coimbra and Alexandre P. Francisco and Lu{\'{\i}}s Veiga},
  title = {An analysis of the graph processing landscape},
  journal = {Journal of Big Data}
}

% Graph frameworks survey 
@article{article:batarfi_survey_graphs,
author = {Batarfi, Omar and Shawi, Radwa El and Fayoumi, Ayman G. and Nouri, Reza and Beheshti, Seyed-Mehdi-Reza and Barnawi, Ahmed and Sakr, Sherif},
title = {Large Scale Graph Processing Systems: Survey and an Experimental Evaluation},
year = {2015},
issue_date = {September 2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-015-0472-6},
doi = {10.1007/s10586-015-0472-6},
abstract = {Graph is a fundamental data structure that captures relationships between different data entities. In practice, graphs are widely used for modeling complicated data in different application domains such as social networks, protein networks, transportation networks, bibliographical networks, knowledge bases and many more. Currently, graphs with millions and billions of nodes and edges have become very common. In principle, graph analytics is an important big data discovery technique. Therefore, with the increasing abundance of large graphs, designing scalable systems for processing and analyzing large scale graphs has become one of the most timely problems facing the big data research community. In general, scalable processing of big graphs is a challenging task due to their size and the inherent irregular structure of graph computations. Thus, in recent years, we have witnessed an unprecedented interest in building big graph processing systems that attempted to tackle these challenges. In this article, we provide a comprehensive survey over the state-of-the-art of large scale graph processing platforms. In addition, we present an extensive experimental study of five popular systems in this domain, namely, GraphChi, Apache Giraph, GPS, GraphLab and GraphX. In particular, we report and analyze the performance characteristics of these systems using five common graph processing algorithms and seven large graph datasets. Finally, we identify a set of the current open research challenges and discuss some promising directions for future research in the domain of large scale graph processing.},
journal = {Cluster Computing},
month = {sep},
pages = {1189–1213},
numpages = {25},
keywords = {Big graph, Experimental evaluation, Graph processing}
}

@article{article:shi_survey_graphs,
author = {Shi, Xuanhua and Zheng, Zhigao and Zhou, Yongluan and Jin, Hai and He, Ligang and Liu, Bo and Hua, Qiang-Sheng},
title = {Graph Processing on GPUs: A Survey},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3128571},
doi = {10.1145/3128571},
abstract = {In the big data era, much real-world data can be naturally represented as graphs. Consequently, many application domains can be modeled as graph processing. Graph processing, especially the processing of the large-scale graphs with the number of vertices and edges in the order of billions or even hundreds of billions, has attracted much attention in both industry and academia. It still remains a great challenge to process such large-scale graphs. Researchers have been seeking for new possible solutions. Because of the massive degree of parallelism and the high memory access bandwidth in GPU, utilizing GPU to accelerate graph processing proves to be a promising solution. This article surveys the key issues of graph processing on GPUs, including data layout, memory access pattern, workload mapping, and specific GPU programming. In this article, we summarize the state-of-the-art research on GPU-based graph processing, analyze the existing challenges in detail, and explore the research opportunities for the future.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {81},
numpages = {35},
keywords = {Graph processing, GAS model, GPU, parallelism, BSP model, graph datasets}
}

% Push-pull efficient
@misc{article:pushpull,
  doi = {10.48550/ARXIV.1804.03327},
  url = {https://arxiv.org/abs/1804.03327},
  author = {Yang, Carl and Buluc, Aydin and Owens, John D.},
  keywords = {Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Implementing Push-Pull Efficiently in GraphBLAS},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

% Fast SpVSpM
@INPROCEEDINGS{article:spvspm:yang,
  author={Yang, Carl and Wang, Yangzihao and Owens, John D.},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium Workshop}, 
  title={Fast Sparse Matrix and Sparse Vector Multiplication Algorithm on the GPU}, 
  year={2015},
  volume={},
  number={},
  pages={841-847},
  doi={10.1109/IPDPSW.2015.77}}
  
% Vertex centric
@inproceedings{article:pregel,
author = {Malewicz, Grzegorz and Austern, Matthew H. and Bik, Aart J.C and Dehnert, James C. and Horn, Ilan and Leiser, Naty and Czajkowski, Grzegorz},
title = {Pregel: A System for Large-Scale Graph Processing},
year = {2010},
isbn = {9781450300322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807167.1807184},
doi = {10.1145/1807167.1807184},
abstract = {Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices, trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations, in each of which a vertex can receive messages sent in the previous iteration, send messages to other vertices, and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient, scalable and fault-tolerant implementation on clusters of thousands of commodity computers, and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.},
booktitle = {Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data},
pages = {135–146},
numpages = {12},
keywords = {distributed computing, graph algorigthms},
location = {Indianapolis, Indiana, USA},
series = {SIGMOD '10}
}

% X-stream edge centric
@inproceedings{article:xstream,
author = {Roy, Amitabha and Mihailovic, Ivo and Zwaenepoel, Willy},
title = {X-Stream: Edge-Centric Graph Processing Using Streaming Partitions},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517349.2522740},
doi = {10.1145/2517349.2522740},
abstract = {X-Stream is a system for processing both in-memory and out-of-core graphs on a single shared-memory machine. While retaining the scatter-gather programming model with state stored in the vertices, X-Stream is novel in (i) using an edge-centric rather than a vertex-centric implementation of this model, and (ii) streaming completely unordered edge lists rather than performing random access. This design is motivated by the fact that sequential bandwidth for all storage media (main memory, SSD, and magnetic disk) is substantially larger than random access bandwidth.We demonstrate that a large number of graph algorithms can be expressed using the edge-centric scatter-gather model. The resulting implementations scale well in terms of number of cores, in terms of number of I/O devices, and across different storage media. X-Stream competes favorably with existing systems for graph processing. Besides sequential access, we identify as one of the main contributors to better performance the fact that X-Stream does not need to sort edge lists during preprocessing.},
booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
pages = {472–488},
numpages = {17},
location = {Farminton, Pennsylvania},
series = {SOSP '13}
}

% comb blas
@article{article:combblas,
author = {Bulu\c{c}, Ayd\i{}n and Gilbert, John R},
title = {The Combinatorial BLAS: Design, Implementation, and Applications},
year = {2011},
issue_date = {November  2011},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {25},
number = {4},
issn = {1094-3420},
url = {https://doi.org/10.1177/1094342011403516},
doi = {10.1177/1094342011403516},
abstract = {This paper presents a scalable high-performance software library to be used for graph analysis and data mining. Large combinatorial graphs appear in many applications of high-performance computing, including computational biology, informatics, analytics, web search, dynamical systems, and sparse matrix methods. Graph computations are difficult to parallelize using traditional approaches due to their irregular nature and low operational intensity. Many graph computations, however, contain sufficient coarse-grained parallelism for thousands of processors, which can be uncovered by using the right primitives. We describe the parallel Combinatorial BLAS, which consists of a small but powerful set of linear algebra primitives specifically targeting graph and data mining applications. We provide an extensible library interface and some guiding principles for future development. The library is evaluated using two important graph algorithms, in terms of both performance and ease-of-use. The scalability and raw performance of the example applications, using the Combinatorial BLAS, are unprecedented on distributed memory clusters.},
journal = {Int. J. High Perform. Comput. Appl.},
month = {nov},
pages = {496–509},
numpages = {14},
keywords = {Markov clustering, parallel graph library, graph analysis, combinatorial BLAS, sparse matrices, software framework, Betweenness centrality, mathematical software, combinatorial scientific computing}
}

% gbtl 
@INPROCEEDINGS{article:gbtl,  author={Zhang, Peter and Zalewski, Marcin and Lumsdaine, Andrew and Misurda, Samantha and McMillan, Scott},  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},   title={GBTL-CUDA: Graph Algorithms and Primitives for GPUs},   year={2016},  volume={},  number={},  pages={912-920},  doi={10.1109/IPDPSW.2016.185}}


% Huawei graphblas
@unpublished{article:hu_graphblas_impl,
 author = "Yzelman, A. N. and Di Nardo, D. and Nash, J. M. and Suijlen, W. J.",
 title = "A {C++} {GraphBLAS}: specification, implementation, parallelisation, and evaluation",
 year = "2020",
 note="Preprint",
 url={http://albert-jan.yzelman.net/PDFs/yzelman20.pdf}
}

% gunrock
@article{article:gunrock_gpu_graph_analytics,
author = {Wang, Yangzihao and Pan, Yuechao and Davidson, Andrew and Wu, Yuduo and Yang, Carl and Wang, Leyuan and Osama, Muhammad and Yuan, Chenshan and Liu, Weitang and Riffel, Andy T. and Owens, John D.},
title = {Gunrock: GPU Graph Analytics},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
issn = {2329-4949},
url = {https://doi.org/10.1145/3108140},
doi = {10.1145/3108140},
abstract = {For large-scale graph analytics on the GPU, the irregularity of data access and control flow, and the complexity of programming GPUs, have presented two significant challenges to developing a programmable high-performance graph library. “Gunrock,” our graph-processing system designed specifically for the GPU, uses a high-level, bulk-synchronous, data-centric abstraction focused on operations on a vertex or edge frontier. Gunrock achieves a balance between performance and expressiveness by coupling high-performance GPU computing primitives and optimization strategies with a high-level programming model that allows programmers to quickly develop new graph primitives with small code size and minimal GPU programming knowledge. We characterize the performance of various optimization strategies and evaluate Gunrock’s overall performance on different GPU architectures on a wide range of graph primitives that span from traversal-based algorithms and ranking algorithms, to triangle counting and bipartite-graph-based algorithms. The results show that on a single GPU, Gunrock has on average at least an order of magnitude speedup over Boost and PowerGraph, comparable performance to the fastest GPU hardwired primitives and CPU shared-memory graph libraries, such as Ligra and Galois, and better performance than any other GPU high-level graph library.},
journal = {ACM Trans. Parallel Comput.},
month = {aug},
articleno = {3},
numpages = {49},
keywords = {GPU, runtime framework, Graph processing}
}

% cusha
@inproceedings{article:cusha,
author = {Khorasani, Farzad and Vora, Keval and Gupta, Rajiv and Bhuyan, Laxmi N.},
title = {CuSha: Vertex-Centric Graph Processing on GPUs},
year = {2014},
isbn = {9781450327497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600212.2600227},
doi = {10.1145/2600212.2600227},
abstract = {Vertex-centric graph processing is employed by many popular algorithms (e.g., PageRank) due to its simplicity and efficient use of asynchronous parallelism. The high compute power provided by SIMT architecture presents an opportunity for accelerating these algorithms using GPUs. Prior works of graph processing on a GPU employ Compressed Sparse Row (CSR) form for its space-efficiency; however, CSR suffers from irregular memory accesses and GPU underutilization that limit its performance. In this paper, we present CuSha, a CUDA-based graph processing framework that overcomes the above obstacle via use of two novel graph representations: G-Shards and Concatenated Windows (CW). G-Shards uses a concept recently introduced for non-GPU systems that organizes a graph into autonomous sets of ordered edges called shards. CuSha's mapping of GPU hardware resources on to shards allows fully coalesced memory accesses. CW is a novel representation that enhances the use of shards to achieve higher GPU utilization for processing sparse graphs. Finally, CuSha fully utilizes the GPU power by processing multiple shards in parallel on GPU's streaming multiprocessors. For ease of programming, CuSha allows the user to define the vertex-centric computation and plug it into its framework for parallel processing of large graphs. Our experiments show that CuSha provides significant speedups over the state-of-the-art CSR-based virtual warp-centric method for processing graphs on GPUs.},
booktitle = {Proceedings of the 23rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {239–252},
numpages = {14},
keywords = {graph representation, coalesced memory accesses, concatenated windows, g-shards, gpu},
location = {Vancouver, BC, Canada},
series = {HPDC '14}
}

% mapgraph
@inproceedings{article:MapGraph,
author = {Fu, Zhisong and Personick, Michael and Thompson, Bryan},
title = {MapGraph: A High Level API for Fast Development of High Performance Graph Analytics on GPUs},
year = {2014},
isbn = {9781450329828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2621934.2621936},
doi = {10.1145/2621934.2621936},
abstract = {High performance graph analytics are critical for a long list of application domains. In recent years, the rapid advancement of many-core processors, in particular graphical processing units (GPUs), has sparked a broad interest in developing high performance parallel graph programs on these architectures. However, the SIMT architecture used in GPUs places particular constraints on both the design and implementation of the algorithms and data structures, making the development of such programs difficult and time-consuming.We present MapGraph, a high performance parallel graph programming framework that delivers up to 3 billion Traversed Edges Per Second (TEPS) on a GPU. MapGraph provides a high-level abstraction that makes it easy to write graph programs and obtain good parallel speedups on GPUs. To deliver high performance, MapGraph dynamically chooses among different scheduling strategies depending on the size of the frontier and the size of the adjacency lists for the vertices in the frontier. In addition, a Structure Of Arrays (SOA) pattern is used to ensure coalesced memory access. Our experiments show that, for many graph analytics algorithms, an implementation, with our abstraction, is up to two orders of magnitude faster than a parallel CPU implementation and is comparable to state-of-the-art, manually optimized GPU implementations. In addition, with our abstraction, new graph analytics can be developed with relatively little effort.},
booktitle = {Proceedings of Workshop on GRAph Data Management Experiences and Systems},
pages = {1–6},
numpages = {6},
keywords = {GPU, Graph analytics, high-level API},
location = {Snowbird, UT, USA},
series = {GRADES'14}
}

% medusa
@ARTICLE{article:medusa,
  author={Zhong, Jianlong and He, Bingsheng},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Medusa: Simplified Graph Processing on GPUs}, 
  year={2014},
  volume={25},
  number={6},
  pages={1543-1552},
  doi={10.1109/TPDS.2013.111}}

% SuiteSparse Sparse Matrix Collection
@article{dataset:sparse_matrix_collection,
  author = {Davis, Timothy A. and Hu, Yifan},
  title = {The University of Florida Sparse Matrix Collection},
  year = {2011},
  issue_date = {November 2011},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {38},
  number = {1},
  issn = {0098-3500},
  url = {https://doi.org/10.1145/2049662.2049663},
  doi = {10.1145/2049662.2049663},
  abstract = {We describe the University of Florida Sparse Matrix Collection, a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading, and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains, include those arising from problems with underlying 2D or 3D geometry (as structural engineering, computational fluid dynamics, model reduction, electromagnetics, semiconductor devices, thermodynamics, materials, acoustics, computer graphics/vision, robotics/kinematics, and other discretizations) and those that typically do not have such geometry (optimization, circuit simulation, economic and financial modeling, theoretical and quantum chemistry, chemical process simulation, mathematics and statistics, power networks, and other networks and graphs). We provide software for accessing and managing the Collection, from MATLAB™, Mathematica™, Fortran, and C, as well as an online search capability. Graph visualization of the matrices is provided, and a new multilevel coarsening scheme is proposed to facilitate this task.},
  journal = {ACM Trans. Math. Softw.},
  month = {dec},
  articleno = {1},
  numpages = {25},
  keywords = {performance evaluation, Graph drawing, sparse matrices, multilevel algorithms}
}

% La-Graph
@misc{misc:la_graph,
  title={LAGraph: Linear Algebra, Network Analysis Libraries, and the Study of Graph Algorithms}, 
  author={Gábor Szárnyas and David A. Bader and Timothy A. Davis and James Kitchen and Timothy G. Mattson and Scott McMillan and Erik Welch},
  year={2021},
  eprint={2104.01661},
  archivePrefix={arXiv},
  primaryClass={cs.MS}
}

% Taskflow library
@article{Huang2022TaskflowAL,
  title={Taskflow: A Lightweight Parallel and Heterogeneous Task Graph Computing System},
  author={Tsung-Wei Huang and Dian-Lun Lin and Chun-Xun Lin and Yibo Lin},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  year={2022},
  volume={33},
  pages={1303-1320}
}

% Boost compute library
@inproceedings{10.1145/2909437.2909454:boost:compute,
    author = {Szuppe, Jakub},
    title = {Boost.Compute: A Parallel Computing Library for C++ Based on OpenCL},
    year = {2016},
    isbn = {9781450343381},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2909437.2909454},
    doi = {10.1145/2909437.2909454},
    abstract = {Boost.Compute is a powerful C++ header-only template library for parallel computing based on OpenCL. It has a layered architecture and acts both as a thin C++ wrapper over the OpenCL API and as a feature-rich interface to high-level constructs that resemble the functionality of the STL and is just as easy to use.Through its template-based design, Boost.Compute seeks to further provide flexible OpenCL support in C++ projects via meta-programming. Meta-programming is not available in standard C-based OpenCL, and OpenCL C++ kernel language is currently only provisional. SYCL is intended as a prospective C++ abstraction layer over OpenCL, but it is still under development and requires a special compiler. Bolt and Thrust are C++-based parallel-computing libraries, but they are tied to specific hardware vendors. Boost.Compute on the other hand is a vendor-neutral solution for GPUs and multi-core CPUs that is available now, and it works with any standard C++ compiler and on all OpenCL platforms.Boost.Compute has been accepted for integration with the official Boost C++ libraries. With this step, and considering the large number of Boost users, usage of Boost.Compute and visibility of OpenCL among C++ developers is likely to increase. This technical presentation is therefore intended as a comprehensive overview of Boost.Compute for current and prospective users of the library and covers the library's overall architecture, its low-level and high-level functionality and advanced topics such as custom functions, closures and lambda expressions. The presentation also describes how a custom template-based OpenCL library can be designed on top of Boost.Compute. Examples are included throughout the presentation to aid in a better understanding. Among others, I will demonstrate how advanced features of the library can lead to a simple and efficient C++-only solution for BLAS calculations. The architectural presentation of the library will be followed by a presentation of current performance results of the library and a comparison with competing solutions. I will conclude the presentation with insights that I gained during Google Summer of Code '15 and my overall experience in contributing to Boost.Compute, which I hope to be of interest to the wider developer community.},
    booktitle = {Proceedings of the 4th International Workshop on OpenCL},
    articleno = {15},
    numpages = {39},
    keywords = {Parallel computing, Boost Compute, Boost C++ Libraries, C++, OpenCL},
    location = {Vienna, Austria},
    series = {IWOCL '16}
}

% What did graphblas wrong
@article{talk:graphblas_did_wrong,
    author = {John R. Gilbert},
    title = {What did the GraphBLAS get wrong?},
    year = {2022},
    url = {https://sites.cs.ucsb.edu/~gilbert/talks/talks.htm},
    journal = {HPEC GraphBLAS BoF}
}