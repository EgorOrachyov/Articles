\section*{Introduction}

Graph model is a natural way to structure data in a number of a real practical tasks, such as graph queries~\cite{article:querying_graph_databases}, graph databases~\cite{paper:redisgraph}, social networks analysis~\cite{article:facebook_large_scale}, RDF data analysis~\cite{article:cfpq_and_rdf_analysis}, bioinformatics~\cite{article:rna_prediction} and static code analysis~\cite{article:dyck_cfl_code_analysis}. In the graph model the entity is represented as a graph vertex. Relations between entities are directed labeled edge. This notation allows to model the domain of the analysis with a little effort, saving complex relationships between objects. What is not easy and clear to do, for example, in a classic \textit{relational} model, based on tables.

Practical real-world graph data tends to be sparse and counts dozens of millions of vertices and billions of edges~\cite{article:facebook_large_scale}. Thus, scalable high-performance graph analysis is demanding area and an actual challenge for a research. There is a big number of ways to attack this challenge~\cite{article:graph_landscape} and the first promising idea is to utilize general-purpose graphic processing units and GPU device for computations. Such existing solutions, as CuSha~\cite{article:cusha} and Gunrock~\cite{article:gunrock} show that utilization of GPUs can improve the performance of graph analysis, moreover it is shown that solutions may be scaled to multi-GPU systems. However, low flexibility and high complexity of API are problems of these solutions.

The second promising thing which provides a user-friendly API for high-performance graph analysis algorithms creation is a GraphBLAS API~\cite{paper:graphblas_foundations}, which provides linear algebra based building blocks to create graph analysis algorithms. The idea of GraphBLAS is based on a well-known fact that linear algebra operations can be efficiently implemented on parallel hardware. Along with that, a graph can be natively represented using matrices: adjacency matrix, incidence matrix, etc. While reference CPU-based implementation of GraphBLAS, SuiteSparse~\cite{article:suite_sparse_for_graph_problems}, demonstrates good performance in real-world tasks, GPU-based implementation is challenging.

One of the challenges in this way is that real data are often sparse, thus underlying matrices and vectors are also sparse, and, as a result, classical data structures and respective algorithms are inefficient. So, it is necessary to use advanced data structures and procedures to implement sparse linear algebra, but the efficient implementation of them on GPUs is hard due to the irregularity of workload and data access patterns. Though such well-known libraries as cuSPARSE~\cite{net:cusparse_docs}, clSPARSE~\cite{article:clsparse}, bhSPARSE~\cite{article:bhsparse}, Cusp~\cite{net:cusplibrary} show that sparse linear algebra operations can be efficiently implemented for GPUs, it is not so trivial to implement GraphBLAS on GPU. First of all, it requires \textit{generalized} sparse linear algebra, thus it is impossible just to reuse existing libraries which are almost all specified for operations over floats with classical element-wise functions. The second problem is specific optimizations, such as masking fusion, which can not be natively implemented on top of existing kernels. Nevertheless, there is a number of implementations of GraphBLAS on GPU, such as GraphBLAST~\cite{yang2019graphblast}, GBTL~\cite{article:gbtl}, which show that GPUs utilization can improve the performance of GraphBLAS-based graph analysis solutions. But these solutions are not portable across different device vendors because they are based on Nvidia Cuda stack.

Although GraphBLAS is solid and mature standard with a number of implementation, it has limitations and shortcomings discussed in a talk given by John R. Gilbert~\cite{talk:graphblas_did_wrong}. Some of them are lack of interoperability and introspection, what is an obstacle on the way of GraphBLAS integration into real-world data analysis pipelines. Implicit zeroes mechanism and masking, which uses mix of engineering and math, leads to unpredictable memory usage in some cases, keeping API complex for both implementation and usage.

Summarizing, there is still no portable and high-performance library, which provides generalized linear-algebra based building blocks for real-world large sparse graph analysis problems. Such a library can potentially solve a number of problems, such as complex user API for particular graph algorithms implementation, GPUs performance and portability issues. Although GraphBLAS standard is a good reference point for implementation, it is still possible design a bit different API. The solution can solve some of technical GraphBLAS limitations while still being coherent with the standard for further co-operation.  