\section{Implementation details}

This section covers the implementation details of the developed library. It gives an insight into the selected storage formats, algorithms for GPU processing, and chosen third-party instruments for the library foundation.

\subsection{General}

Developed spla library is written using C++17 language and standard library. CMake 3.17 is used as build configuration tool. Ninja library is used to generate platform specific build files. Library supports build on Linux (tested on Ubuntu 20.04), Windows (tested on 10) and macOS (tested on Catalina). Git used as version control system. The source code of the project is hosted on a GitHub page. Library is compiled into shared executable object with respect to the target platform naming convention and object extension.\\

Project directory has the following structure.\\

\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{ include}. Public library interface files in \textit{.hpp} format. 
    {
    \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
        \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{spla}. Public library C++ interface header files.
        \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{spla-c}. Public library C99-compatible inteface header files.
    \end{itemize}
    }
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{src}. Source files, compiled into shared executable object.
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{deps}. Third-party project dependencies stored as a source code.
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{tests}. Directory with unit tests files for Google Tests.
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{examples}. Example applications for graph algorithms.
    \item {\fontspec{Symbola}\symbol{"1F5C0}} \textit{python}. Source code for a python package for spla library.
    \item {\fontspec{Symbola}\symbol{"1F5CE}} \textit{CMakeLists.txt}. Root cmake file of the project.
    \item {\fontspec{Symbola}\symbol{"1F5CE}} \textit{build.py}. Python script to build library artifacts.
    \item {\fontspec{Symbola}\symbol{"1F5CE}} \textit{generate.py}. Python script to generate \textit{.hpp} from \textit{.cl} files.
    \item {\fontspec{Symbola}\symbol{"1F5CE}} \textit{run\_tests.py}. Python script to run unit tests.
    \item {\fontspec{Symbola}\symbol{"1F5CE}} \textit{bump\_version.py}. Python script to upgrade package version.
\end{itemize}

\subsection{Dependencies}

This section briefly covers third-party libraries and projects, utilized by the spla library.\\

\textbf{Khronos OpenCL headers}. C-compatible OpenCL header files library developed and maintained by the Khronos Consortium. Since the OpenCL is an public API declared as a standard, its support is optional for operating systems and programming environments. In order to access OpenCL functions the respective header files with OpenCL functions declarations, signatures, constants, defines and other symbols must be manually used by a project. An alternative is to install this headers to a computer manually. But this step is error prone and less flexible.\\

\textbf{Khronos OpenCL hpp headers}. C++-compatible OpenCL header files library developed and maintained by the Khronos Consortium. Since the spla project is written using modern C++ standard, safe C++ bindings for an OpenCL code must be used. 

OpenCL C++ bindings provide a memory and exceptions safe, object-oriented API, which relies on a standard containers and data structures. It allows to automate and simplify objects lifetime management. \\

\textbf{Khronos OpenCL ICD loader}. OpenCL installable client driver (ICD) library developed and maintained by the Khronos Consortium. It provides a mechanism to allow developers to build applications against an ICD loader rather than linking their applications against a specific OpenCL implementation. 

The ICD loader is responsible for: exporting OpenCL API entry points, enumerating OpenCL implementations, forwarding OpenCL API calls to the correct implementation.

The ICD mechanism is required in order to load dynamically particular OpenCL implementation at runtime. The motivation for that is the vast variety of different OpenCL implementations. Each implementation can be shipped with a GPU driver. The system can have a number of different GPUs with distinct drivers and vendors. Thus, it is not possible to know a target implementation a priory.

The ICD loader is bundled inside the spla dynamic library during build process. Loader is used on a library startup. It quires available OpenCL drivers in the system. Then it selects one to use in the application. The selection is based on a user parameters. Then it loads OpenCL symbols through shared library mechanism and initializes global OpenCL state.\\

\textbf{GTest}. GTest is an open source unit-testing library for C++ projects. This library is developed and maintained by a Google company. The library provides flexible macro system for declaring unit tests and assertions. This library is used extensively for testing a spla functionality. Project units testes with gtest are stored in a \textit{tests} directory.\\

\textbf{Cxxopts}. Cxxopts is an open-source command-line arguments parsing library for C++ projects. This library automates processing of executable arguments, passed in a classic \textit{argc \& argv} fashion. Library is used a an auxilary tool for example applications, built using library API. Example applications used for a benchmarking of the library performance.\\

\subsection{Automation}

The library source code is hosted on a GitHub platform. This platform provides a convenient \textit{actions} mechanism, also called \textit{workflows}. It allows to automate the process of a continuous project changes integration and continuous delivery of the project artifacts to potential users. The GitHub repository is configure with the following list of scripts for automation.

\begin{itemize}
    \item \textbf{build}. The build action, which compiles the source code of the library, executable examples and test for three target platform: Windows 10, Ubuntu (20.04) and macOS (for x64 and arm architectures). The artifacts of a build process are published automatically in a GitHub repository. These artifacts are reused in a later step, when the python package is assembled to be pushed to either test or retail index repository.  
    \item \textbf{clang-format}. The formatting script which automatically checks the conformance of the library header and source files. The project uses a clang-format tool to check the code style of the project automatically. Definition of a code style is stored in repository as a configuration file in special format.  
    \item \textbf{deploy}. Deployment script is responsible for an automated publishing of a spla python package to the python package index (PyPI) repository. This action assembles a bundle, which stores python sources as well as artifacts for all platforms from \textit{build} action. Action automatically pushes package to the PyPI using credentials, stored in a repository. The action is triggered automatically on commits to special \textit{release} branch. This is supposed to happen on a major and minor library versions' releases. 
    \item \textbf{deploy-test}. Deployment script similar to \textit{deploy} action. The difference is that this script pushes package to the Test PyPI repository for testing purposes. The action is triggered automatically on commits to special \textit{pre-release} branch.
    \item \textbf{docs-cpp}. Script which assembles C/C++ library documentation using Oxygen format. The documentation is represented by a set of html pages. These pages are deployed automatically to the project website page. 
    \item \textbf{docs-pythos}. Script which assembles python package documentation using python docs library. The documentation is represented by a set of html pages. These pages are deployed automatically to the project website page. 
\end{itemize}

\subsection{Interface}

This section the technical details of the library public interface are covered. Interface includes matrix, vector and scalar containers for a typed data storage, operations for the execution, algebraic functions for operations customization, etc.\\

\textbf{Containers}. Library provides \textit{vector}, \textit{matrix} and \textit{scalar} data containers. Each container can be parameterised with a type of stored values. The actual storage mechanism is automated and is hidden from a user. Matrix and vector containers can store data in multiple formats at the same time. In order to access them, the library provides opaque interface, which allows to incrementally build containers, query elements, inspect its properties an state. List of supported operations to access containers is shown in a table~\ref{tab:containers}.\\

\begin{table}[tbp]
\caption{A list of the supported operations to access vector and matrix containers.}
\begin{center}
    \rowcolors{2}{black!2}{black!10}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Method} & \textbf{Description} \\ \hline
    \hline
    \textit{Matrix} & Matrix constructor from type T and dimensions\\ \hline
    \textit{Vector} & Vector constructor from type T and dimension\\ \hline
    \hline
    \textit{clear} & Empty vector or matrix\\ \hline
    \hline
    \textit{get\_nrows} & Query number of rows for a matrix or vector\\ \hline
    \textit{get\_ncols} & Query number of columns for a matrix or vector\\ \hline
    \textit{get\_type} & Query the type T of elements \\ \hline
    \hline
    \textit{set\_<T>} & Set element of type T at index $\langle i,j\rangle$\\ \hline
    \textit{get\_<T>} & Get element of type T at index $\langle i,j\rangle$\\ \hline
    \end{tabular}
    \label{tab:containers}
\end{center}
\end{table}

\textbf{Operations}. An expression for the execution is constructed as a schedule object using library API. The primitive unit of the schedule is a single task. Task represents an operation over matrices, vectors and scalars. Library provides a number of common and widely used operations for evaluation. List of supported operations provided in the table~\ref{tab:operations}.\\

\begin{table}[tbp]
\caption{A list of the spla mathematical operations for computations.}
\begin{center}
    \rowcolors{2}{black!2}{black!10}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Operation}     & \textbf{Math equivalent}               & \textbf{Description}           \\ \hline 
    \hline
    \textit{masked vxm}    & $r_i = (vM)_i, \forall i: f(m_i)$   & Masked vector-matrix product   \\ \hline
    \textit{masked mxv}    & $r_i = (Mv)_i, \forall i: f(m_i)$   & Masked matrix-vector product   \\ \hline 
    \hline
    \textit{masked assign} & $r_i = s, \forall i: f(m_i)$        & Masked vector scalar assignment\\ \hline 
    \hline
    \textit{reduce}        & $s = \Sigma v_i$                       & Vector reduce to scalar        \\ \hline
    \textit{select count}  & $s = |\{v_i: f(v_i)\}|$                & Vector select count            \\ \hline
    \end{tabular}
    \label{tab:operations}
\end{center}
\end{table}

\textbf{Element-wise functions}. The core feature of the library is the ability to parameterise math operations mentioned above with arbitrary algebraic element-wise binary and unary functions. The list of build-in functions, which supported for both CPU and GPU computations, is depicted in the table~\ref{tab:ewise}. The operations can be used for any of build type such int, uint and float values. The only exception is bit-wise operations, which can be applied only to integral types.\\

\begin{table}[tbp]
\caption{A list of the spla element-wise mathematical functions to parameterise operations.}
\begin{center}
    \rowcolors{2}{black!2}{black!10}
    \begin{tabular}{|l|l|l|l|}
    \hline
    \textbf{Function} & \textbf{Equivalent} & \textbf{Type} & \textbf{Description} \\ \hline
    \hline
    \textit{plus}   & $r = a + b$ & function & Sum of two elements \\ \hline
    \textit{minus}  & $r = a - b$ & function & Difference of two elements \\ \hline
    \textit{mult}   & $r = a * b$ & function & Product of two elements \\ \hline
    \textit{div}    & $r = a / b$ & function & Division of two elements \\ \hline
    \hline
    \textit{min}    & $r = min(a, b)$ & function & Minimum value \\ \hline
    \textit{max}    & $r = max(a, b)$ & function & Maximum value \\ \hline
    \hline
    \textit{first}  & $r = a$ & function & First argument of function \\ \hline
    \textit{second} & $r = b$ & function & Second argument of function \\ \hline
    \textit{one}    & $r = 1$ & function & Identity element \\ \hline
    \hline
    \textit{and}    & $r = a \land b$  & function & Bit-wise product \\ \hline
    \textit{or}     & $r = a \lor b$   & function & Bit-wise sum\\ \hline
    \textit{xor}    & $r = a \oplus b$ & function  & Bit-wise exclusive sum \\ \hline
    \hline
    \textit{eqzero} & $a == 0$  & predicate & Check equals zero \\ \hline
    \textit{nqzero} & $a\neq 0$ & predicate & Check not-equals zero \\ \hline
    \end{tabular}
    \label{tab:ewise}
\end{center}
\end{table}

\textbf{Signatures}. Library heavily relies on a built-in mechanism of automated reference counting of objects. Each object has an atomic counter, which tracks number or references. When the counter reaches the zero, it frees up the object. This mechanism used for safe arguments passing around library and for safe marshaling of objects through C and python APIs.

Library employs explicit operations signatures. All arguments and parameters must passed by the user through operation interface. If operation has variations or provides tweaking, all parameters must be specified.

As an example, consider the signature of the masked matrix-vector product operation in a listing~\ref{alg:spla_op_example}. This is a procedure, which can be loaded from a dynamic or shared library. As the result of an invocation it returns special \textit{Status} enumeration value. Library uses no exceptions. Thus, error codes are employed. It is standard practice for libraries with C-compatible API. 

The procedure takes nine input in lines \textbf{1 -- 9} and one optional output argument in line \textbf{10}. The \textit{r} is a vector where to store result of operation execution. The \textit{mask} is a vector of the same dimension as r, which is used to update only selected entries of the vector r. Matrix \textit{M} and vector \textit{v} are the actual primitives to multiply. Actual algebraic element-wise functions from multiplication and addition are passed as \textit{op\_multiply} and \textit{op\_add}. The predicate to filter result by a mask passed as a \textit{op\_select}. Note, that functions in the library are first-class objects, which can be manipulated as any other library object. The identity element for product evaluation is passed as \textit{init} scalar.

An optional parameter is a Descriptor \textit{desc} object. It has the same usage as in a GraphBLAS standard. Descriptor stores additional parameters, which configure actual execution of the operation, occupation, preferred device, mode, etc. It can be used to optimize the execution of particular operations for edge cases.

Finally, the procedure accepts an optional output argument. It is a pointer to the handle of the schedule task object. If pointer is null, then the procedure executes the operation in an imperative fashion. If this pointer is not null, then the implementation creates a deferred task for the execution, stores reference to this task in provided pointer and returns. In this case, the returned task can be used to construct schedule object, which can be submitted at once as a whole. The scheduling mechanism implemented as previously described in architecture section.

\lstset{style=codelistingstyle}

\begin{algorithm}[tbp]
\floatname{algorithm}{Listing}
\caption{The C++ signature of the spla masked matrix-vector product.}
\label{alg:spla_op_example}
\begin{lstlisting}[language=C++]
SPLA_API Status exec_mxv_masked(/* in  */ ref_ptr<Vector>        r,
                                /* in  */ ref_ptr<Vector>        mask,
                                /* in  */ ref_ptr<Matrix>        M,
                                /* in  */ ref_ptr<Vector>        v,
                                /* in  */ ref_ptr<OpBinary>      op_multiply,
                                /* in  */ ref_ptr<OpBinary>      op_add,
                                /* in  */ ref_ptr<OpSelect>      op_select,
                                /* in  */ ref_ptr<Scalar>        init,
                                /* in  */ ref_ptr<Descriptor>    desc = nullptr,
                                /* out */ ref_ptr<ScheduleTask>* task_hnd = nullptr);
\end{lstlisting}
\end{algorithm}

\subsection{Data storage}

The library is implemented following storage schema, introduced and described in a previous section. In this schema each data container, such as a matrix or vector has a number of decorations or formats, which can be simultaneously assigned to the container. It introduces duplication. However, it gives the flexibility for the choice of target device and particular implementation algorithm for the execution.

The same container can have a number of formats allocated at the same time. The storage manager automatically controls the validity of the data. This mechanism allows to cache the same data in both RAM and VRAM memory. Since the RAM in most cases has a order of magnitude larger size, the duplication is negligible.

The vector storage container supports following formats.

\begin{itemize}
    \item \textbf{CPU dictionary of keys (DoK)}. The format of the vector, where non-zero entries stored as a dictionary. Storage space is proportional to a number of values. It gives fast query and insertion operations at cost of inefficient memory layout. This format is used for incremental builds of container on a CPU side.
    \item \textbf{CPU list of coordinates (COO).} This format used for sparse vector representation. Data in this format stored as a list of indices and as a list of values. Memory space proportional to the number of non-zero entries. Used to prepare data for GPU source \& target transfer.
    \item \textbf{CPU dense vector.} This format used for a dense vector representation. Data in this format stored as a large array of values with the same size as vector dimension. Memory space proportional to the vector dimension. Memory consumption can be excessive on vectors with over 1M elements. Used to prepare data for GPU source \& target transfer.
    \item \textbf{OpenCL list of coordinates (COO)}. It is GPU representation of a COO format using OpenCL API. Used for sparse vector manipulation on GPU side. 
    \item \textbf{OpenCL dense vector}. It is GPU representation of a COO format using OpenCL API. Used for a dense vector manipulation on GPU side.
\end{itemize}

The matrix storage container supports following formats.

\begin{itemize}
    \item \textbf{CPU dictionary of keys (Dok)}. This format is used for an incremental matrix building on a CPU side as it is done for a vector. The memory space used by this format is proportional to the number of non-zero entries. This format provides fast query and insertion operations at cost of inefficient memory layout.
    \item \textbf{CPU compressed sparse row (CSR)}. Compressed sparse row is one of the most common formats for a sparse matrix representation. The data is stored in a form of three arrays: rows offsets, column indices and column values. Rows values are packed. They are stored continuously. Column indices of each value in a row and each value are packed together in index and value arrays. Offsets to the start of a particular row are stored in offsets buffer. Total memory cost of the storage proportional to the number of entries in sparse arrays. Offsets buffers always allocated using total number of rows of a matrix. 
    \item \textbf{OpenCL compressed sparse row (CSR)}. This is a CSR format implementation for a GPU computations using OpenCL. Data to this storage format is transfered from a CPU CSR format representation. GPU CSR allows fast access to a random matrix row. However, the access on a particular value in a row is linear and requires consecutive reads. It is more suitable for GPUs processing, where each row can be processed in parallel by separate SIMD processors or compute units.
\end{itemize}

\subsection{Kernel management}

OpenCL provides a flexible but yet complex way to manage GPU executable code. The OpenCL program is text file written using some sort of a C-language with special extensions. The program must be compiled at runtime before the actual usage. The compilation process may take a couple of seconds. It is not feasible to compile a program for each invocation of an OpenCL operation. Thus, the management mechanism is required.

The library implements this mechanism in a form of a runtime program cache. Main entities of this mechanism are listed bellow.

\begin{itemize}
    \item \textbf{CLProgram}. Is a wrapper for the OpenCL program. It stores compiled program as well as used definitions, symbols and cached kernels for the invocation.
    \item \textbf{CLPorgramBuilder}. Program builder provides a mechanism for a flexible runtime program construction. It allows to parameterise source code of the program with particular types, functions, constants, etc. It is required since programs are generalized and unaware of particular types of processed elements such as int, float, uint. The builder automatically checks if program aready compiled and cached. It avoids unnecessary compilation.
    \item \textbf{CLProgramCache}. Program cache is a global runtime storage of all compiled programs. It uses source code of programs as keys. Thus, any variation of a particular algorithm implementation can be cached and reused as many times as needed.
\end{itemize}

\subsection{Running example}

\lstset{style=codelistingstyle}

\begin{algorithm}[]
\floatname{algorithm}{Listing}
\caption{Breadth-first search algorithm implementation using Spla API}
\label{alg:spla_bfs_example}
\begin{lstlisting}[language=C++]
SPLA_API Status spla::bfs(const ref_ptr<Vector>&     v,
                          const ref_ptr<Matrix>&     A,
                          uint                       s,
                          const ref_ptr<Descriptor>& desc) {
    const auto N = v->get_n_rows();

    ref_ptr<Vector> front_prev     = make_vector(N, INT);
    ref_ptr<Vector> front          = make_vector(N, INT);
    ref_ptr<Scalar> front_size     = make_int(1);
    ref_ptr<Scalar> depth          = make_int(1);
    ref_ptr<Scalar> zero           = make_int(0);
    int             current_level  = 1;
    int             front_size     = -1;
    int             discovered     = 1;
    bool            front_empty = false;
    
    front_prev->set_int(s, 1);

    while (!front_empty) {
        depth->set_int(current_level);
        exec_v_assign_masked(v, front_prev, depth, SECOND_INT, NQZERO_INT, desc);
        exec_vxm_masked(front, v, front_prev, A, BAND_INT, BOR_INT, EQZERO_INT, zero, desc);
        exec_v_reduce(front_size, zero, front, PLUS_INT, desc);
        
        front_size->get_int(front_size);
        front_empty = front_size == 0;
        discovered += front_size;
        current_level += 1;

        std::swap(front_prev, front);
    }

    return Status::Ok;
}
\end{lstlisting}
\end{algorithm}

As an example of the developed spla library usage consider breadth-first search algorithm implementation shown in the code listing~\ref{alg:spla_bfs_example}. 

Algorithm procedure is declared in the \textit{spla} namespace in the public interface file. The implementation of the algorithm is defined in the private cpp source file, compiled into shared object library. Procedure expects as an input reference to the result vector $v$ where to store reached depths of vertices, adjacency matrix of the undirected graph $A$, index of the start vertex $s$ and an optional descriptor to tweak algorithm execution.

Before actual execution, the graph size saved as $N$ in line \textbf{5}. Then in lines \textbf{7 -- 11} data containers required for the algorithm execution are allocated. The front of the search is created in lines \textbf{7 -- 8}. Two instances are used, since the update of the front for the new iteration requires the previous version of the front. In order to avoid unintentional costly GPU memory allocations, these fronts allocated explicitly and kept until the end of the procedure. The front size scalar is created in line \textbf{9}. Scalar holding current depths and scalar with identity elements are created in lines \textbf{10 -- 11}. A number state tracking variables are created in lines \textbf{12 -- 15}. They are used to track current state of the search.

Initial frontier start vertex is set in line \textbf{20}. The starting depths of the source vertex is 1. Yet unreached vertices or unreachable vertices have a depth equal to 0 by default.

The algorithm iterates in the \textit{while loop} in lines \textbf{22 -- 34} until frontier of vertices to visit is not empty. Iteration operations executed in lines \textbf{23 -- 26}. Firstly, the scalar is updated with new depth value. Then, this depth is assigned to the result vector using frontier from the previous iteration as a mask. After assignment new frontier is obtained as a single search step from front vertices to next vertices through vector-matrix product. Note, that vector $v$ used as mask to filter all already visited vertices. The special predicated for that is used. Only mask values which equal to zero will be touched. It implies to the update only of yet unreached vertices. 

After the execution the vector $v$ for each graph vertex stores either the depth of the vertex or zero in the case if this vertex is not reachable from the BFS source vertex $s$. Since library API relies on C++ RAII mechanism, no explicit resources cleanup is required after the execution.