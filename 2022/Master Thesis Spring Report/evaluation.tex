\section{Evaluation}

\subsection{Experiment description}

For performance analysis of the proposed solution, we evaluated a few most common graph algorithms using real-world sparse matrix data. As a baseline for comparison we chose LAGraph~\cite{misc:la_graph} in connection with SuiteSparse~\cite{article:suite_sparse_for_graph_problems} as a CPU tool, Gunrock~\cite{article:gunrock} and GraphBLAST~\cite{yang2019graphblast} as a Nvidia GPU tools. Also, we tested algorithms on several devices with distinct OpenCL vendors in order to validate the portability of the proposed solution. In general, these evaluation intentions are summarized in the following research questions.\\

\textbf{Research questions}. In order to structure the experimental study, the following research questions are formulated.

\begin{itemize}
    \item[\textbf{RQ1}] What is the performance of the proposed solution relative to existing tools for both CPU and GPU analysis?
    
    \item[\textbf{RQ2}] What is the portability of the proposed solution with respect to various device vendors and OpenCL runtimes?
\end{itemize}

\textbf{Setup}. For evaluation, we use a PC with Ubuntu 20.04 installed, which has 3.40Hz Intel Core i7-6700 4-core CPU, DDR4 64Gb RAM, Intel HD Graphics 530 integrated GPU, and Nvidia GeForce GTX 1070 dedicated GPU with 8Gb on-board VRAM. Host programs were compiled with GCC v9.3.0. Programs using CUDA were compiled with GCC v8.4.0 and Nvidia NVCC v10.1.243. Release mode and maximum optimization level were enabled for all tested programs. Data loading time, preparation, format transformations, and host-device initial communications are excluded from time measurements. All tests are averaged across 10 runs. Additional warm-up run for each test execution is excluded from measurements.\\

\textbf{Graph algorithms}. For preliminary study \textit{breadth-first search} (BFS) and \textit{triangles counting} (TC) algorithms were chosen, since they allow analyse the performance of \textit{vxm} and \textit{mxm} operations, rely heavily on \textit{masking}, and utilize \textit{reduction} or \textit{assignment}. BFS implementation utilizes automated vector storage sparse-to-dense switch and only \textit{push optimization}. TC implementation uses masked \textit{mxm} of source lower-triangular matrix multiplied by itself with second transposed argument.\\

\textbf{Dataset}. Nine matrices were selected from the Sparse Matrix Collection at University of Florida~\cite{dataset:sparse_matrix_collection}. Information about graphs is summarized in Table~\ref{dataset:info}. All datasets are converted to undirected graphs. Self-loops and duplicated edges are removed.\\

\begin{table}[tbp]
\caption{Dataset description.} 
\begin{center}
    \rowcolors{2}{black!2}{black!10}
    \begin{tabular}{|l|r|r|r|}
    \hline
    Dataset & Vertices  & Edges & Max Degree \\
    \hline
    \hline
    coAuthorsCiteseer & 227.3K &   1.6M &    1372 \\
    coPapersDBLP      & 540.4K &  30.4M &    3299 \\
    hollywood-2009    &   1.1M & 113.8M &  11,467 \\
    roadNet-CA        &   1.9M &   5.5M &      12 \\
    com-Orkut         &     3M &   234M &   33313 \\
    cit-Patents       &   3.7M &  16.5M &     793 \\
    rgg\_n\_2\_22\_s0 &   4.1M &  60.7M &      36 \\
    soc-LiveJournal   &   4.8M &  68.9M &  20,333 \\
    indochina-2004    &   7.5M & 194.1M & 256,425 \\
    \hline
    \end{tabular}
    \label{dataset:info}
\end{center}
\end{table}

\subsection{Results}

\begin{table}[h]
\caption{Breadth-first search algorithm evaluation results.\\Time in milliseconds (lower is better).} 
\begin{center}
    \begin{tabular}{|l|r|r|r|r|r|}
    \hline
    \multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{Nvidia} & \multicolumn{2}{c|}{Intel} \\
    \cline{2-6}
    & GR & GB & SP & SS & SP \\
    \hline
    \hline
    \rowcolor{black!10} hollywood-2009    &  20.3 &  82.3 &   36.9 &   23.7 &   303.4 \\
    \rowcolor{black!2 } roadNet-CA        &  33.4 & 130.8 & 1456.4 &  168.2 &   965.6 \\
    \rowcolor{black!10} soc-LiveJournal   &  60.9 &  80.6 &   90.6 &   75.2 &  1206.3 \\
    \rowcolor{black!2 } rgg\_n\_2\_22\_s0 &  98.7 & 414.9 & 4504.3 & 1215.7 & 15630.1 \\
    \rowcolor{black!10} com-Orkut         & 205.2 & -- -- &  117.9 &   43.2 &   903.6 \\
    \rowcolor{black!2 } indochina-2004    &  32.7 & -- -- &  199.6 &  227.1 &  2704.6 \\
    \hline
    \hline
    \multicolumn{6}{l}{Tools: Gunrock (GR), GraphBLAST (GB), SuiteSparse (SS), Spla (SP).} \\
    \end{tabular}
    \label{results:bfs}
\end{center}
\end{table}

\begin{table}[h]
\caption{Triangles counting algorithm evaluation results.\\Time in milliseconds (lower is better).} 
\begin{center}
    \begin{tabular}{|l|r|r|r|r|r|}
    \hline
    \multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{Nvidia} & \multicolumn{2}{c|}{Intel} \\
    \cline{2-6}
    & GR & GB & SP & SS & SP \\
    \hline
    \hline
    \rowcolor{black!10} coAuthorsCiteseer &   2.1 &    2.0 &    9.5 &    17.5 &    64.9 \\
    \rowcolor{black!2 } coPapersDBLP      &   5.7 &   94.4 &  201.9 &   543.1 &  1537.8 \\
    \rowcolor{black!10} roadNet-CA        &  34.3 &    5.8 &   16.1 &    47.1 &   357.6 \\
    \rowcolor{black!2 } com-Orkut         & 218.1 & 1583.8 & 2407.4 & 23731.4 & 15049.5 \\
    \rowcolor{black!10} cit-Patents       &  49.7 &   52.9 &   90.6 &   698.3 &   684.1 \\
    \rowcolor{black!2 } soc-LiveJournal   &  69.1 &  449.6 &  673.9 &  4002.6 &  3823.9 \\
    \hline
    \hline
    \multicolumn{6}{l}{Tools: Gunrock (GR), GraphBLAST (GB), SuiteSparse (SS), Spla (SP).} \\
    \end{tabular}
    \label{results:tc}
\end{center}
\end{table}

Tables~\ref{results:bfs} and~\ref{results:tc} present results of the evaluation and compare the performance of Spla (proposed library) against other tools on different execution platforms. Tools are grouped by the type of device for the execution, where either Nvidia or Intel device is used. Cell left empty if tested tool failed to analyze graph due to \textit{out of memory} exception.\\

\textbf{RQ1} \textit{What is the performance of the proposed solution relative to existing tools for both CPU and GPU analysis?}

In general, Spla BFS shows acceptable performance, especially on graphs with large vertex degrees, such as soc-LiveJournal and com-Orkut. On graphs roadNet-CA and rgg it has a significant performance drop due to the nature of underlying algorithms and data structures. Firstly, the library utilizes immutable data buffers. Thus, iteratively updated dense vector of reached vertices must be copied for each modification, which dominates the performance of the library on a graph with a large search depth. Secondly, Spla BFS does not utilize \textit{pull optimization}, which is critical in a graph with a relatively small search frontier and with a large number of reached vertices. 

Spla TC has a good performance on GPU, which is better in all cases than reference SuiteSparse solution. But in most tests GPU competitors, especially Gunrock, show smaller processing times. GraphBLAST shows better performance as well. The library utilizes a masked SpGEMM algorithm, the same as in GraphBLAST, but without \textit{identity} element to fill gaps. Library explicitly stores all non-zero elements, and uses mask to reduce only non-zeros while evaluating dot products of rows and columns. What causes extra divergence inside work groups. 

Gunrock shows nearly the best average performance due to its specialized and optimized algorithms. Also, it has good time characteristics on a mentioned earlier roadNet-CA and rgg in BFS algorithm. GraphBLAST follows Gunrock and shows good performance as well.  But it runs out of memory on two significantly large graphs con-Orkut and indochina-2004. Spla does not rut out of memory on any test due to the simplified storage scheme.\\

\textbf{RQ2} \textit{What is the portability of the proposed solution with respect to various device vendors and OpenCL runtimes?}

On a Nvidia device Spla algorithms' performace in general is acceptable. But it still slower than its competitors, such as Gunrock or GraphBLAST. However, in both BFS and TC the performance gap is maintained in a predictable fashion.

Spla BFS algorithm suffers a lot on a Intel device compared to SuiteSparse implementation. This is caused due to intense data access and relatively small computations parallelism though traversal. On-chip memory has larger latency, so CPU optimized solution shows better results. 

However, on Intel device Spla TC algorithm shows better performance compared to SuiteSparse on com-Orkut, cit-Patents, and soc-LiveJournal. A possible reason is the large lengths of processed rows and columns in the product of matrices. So, even embedded GPUs can improve the performance of graph analysis in some cases.\\

Evaluation of proposed solution for real-world graph analysis allows to conclude, that initial OpenCL-based operations implementation with a limited set of optimizations has promising performance compared to other tools and can be easily executed on devices of multiple vendors, which gives significant flexibility in a choice of HPC hardware. 

% \section{Экспериментальное исследование}

% В предыдущих главах были рассмотрены как особенности проектирования и разработки библиотеки примитивов разреженной линейной булевой алгебры, 
% так и детали реализации алгоритма поиска путей с КС ограничениями на основе тензорного произведения.
% В данной секции предлагается рассмотреть результаты экспериментального исследования полученных артефактов.
% Основная задача исследования: оценить производительность как библиотеки, так и алгоритма, в задачах анализа данных близких к реальным, и сравнить полученные показатели с другими схожими решениями в области.

% \subsection{Постановка экспериментов}

% Для экспериментов использовалась рабочая станция с процессором Intel Core i7-6790, тактовой частотой 3.40GHz, RAM DDR4 с объемом памяти 64Gb, видеокартой GeForce GTX 1070 с 8Gb VRAM, под управлением ОС Ubuntu 20.04.

% \subsubsection*{Исследовательские вопросы}

% Для того, чтобы структурировать исследование, были сформулированы следующие вопросы.

% \begin{itemize}
%   \item[\textbf{В1:}] Какова производительность отдельных операций реализованной библиотеки примитивов разреженной линейной булевой алгебры на GPGPU по сравнению с существующими аналогами?
   
%   \item[\textbf{В2:}] Какова производительность реализованного алгоритма поиска путей через тензорное произведение на GPGPU  по сравнению с существующими аналогами, также полагающимися на примитивы линейной алгебры? 
% \end{itemize}

% В1 направлен на исследование эффективности отдельных матричных операций в реализованной библиотеке. В качестве таких операций выступают \textit{матричное умножение} и \textit{матричное сложение} в булевом полукольце, как наиболее распространенные и критически важные операции в прикладных алгоритмах. Для сравнения производительности в этих операциях предлагается использовать популярные существующие библиотеки разреженной линейной алгебры для платформ Nvidia Cuda, OpenCL и CPU. В качестве таких библиотек были выбраны CUSP и cuSPARSE для Nvidia Cuda, clSPARSE для OpenCL, и SuiteSparse для CPU. CUSP предоставляет реализацию операций, основанную на шаблонах для параметризации используемого типа данных, однако библиотека не делает каких-либо дополнительных оптимизация конкретно для булевых значений. cuSPARSE и clSPARSE предоставляют операции только для основных типов данных с плавающей запятой. Однако данное ограничение можно обойти, если интерпретировать ненулевые значения как \textit{true}. Библиотека SuiteSparse является эталонной реализацией GraphBLAS API и имеет встроенное булево полукольцо для вычислений.

% В2 направлен на исследование эффективности реализованного алгоритма поиска путей с КС ограничениями на основе тензорного произведения и на оценку ускорения, полученного при вычислениях на GPU как в этом алгоритме, так и в алгоритме Рустама Азимова~\cite{inproceedings:cfqp_matrix_with_single_source}, который также полагается на операции линейной булевой алгебры. Данный алгоритм также реализован с использованием разработанного в данной работе Python-пакета pycubool, что делает исследование корректным. Также для сравнения будут использованы реализации этих алгоритмов на основе pygraphblas для вычислений на CPU, чтобы оценить вклад GPGPU-вычислений в ускорение работы алгоритмов. В качестве тестовой инфраструктуры используется стенд CFPQ-PyAlgo, описанный в разделе~\ref{section:algo_impl}. 

% \subsubsection*{Набор данных}

% Для замеров производительности отдельных операций реализованной библиотеки были выбраны 10 различных квадратных матриц из известной коллекции университета Флориды~\cite{net:sp_matrix_data_florida} для проверки эффективности алгоритмов, реализующих операции над разряженными матрицами. 
% Информация о матрицах представлена в таблице~\ref{table:sparse_matrices}. 
% Для обозначения числа ненулевых элементов используется аббревиатура \textit{Nnz} (англ. number of non-zero elements). 
% В таблице приведено официальное название матрицы, количество строк (соответствует числу столбцов), количество ненулевых элементов в матрице, соотношение ненулевых элементов к числу строк, максимальное количество ненулевых элементов в строке, а также количество ненулевых элементов в производных матрицах, полученных умножением исходной матрицы на себя, что обозначается как степень $M^2$, и поэлементным сложением исходной матрицы с собой также возведенной в степень, что обозначается как $M + M^2$.
% Вычисление данных артефактов имитирует шаг транзитивного замыкания.
% Эффективное вычисление этого шага во многом определяет производительность конечных пользовательских алгоритмов на графах.

% \begin{table}[h]
% \begin{center}
% \caption{Разреженные матричные данные}
% \label{table:sparse_matrices}
% % \scriptsize
% \rowcolors{2}{black!2}{black!10}
% \scalebox{0.7}{
% \begin{tabular}{|l|r|r|r|r|r|r|}
% \hline
% Матрица $M$      & Кол-во Строк $R$ & Nnz $M$    & Nnz/$R$ & Max Nnz/$R$ & Nnz $M^2$  & Nnz $M + M^2$    \\
% \hline
% \hline
% wing             &    62,032      &   243,088    & 3.9   & 4         &    714,200     &    917,178       \\
% luxembourg\_osm  &   114,599      &   239,332    & 2.0   & 6         &    393,261     &    632,185       \\
% amazon0312       &   400,727      & 3,200,400    & 7.9   & 10        & 14,390,544     & 14,968,909       \\
% amazon-2008      &   735,323      & 5,158,388    & 7.0   & 10        & 25,366,745     & 26,402,678       \\
% web-Google       &   916,428      & 5,105,039    & 5.5   & 456       & 29,710,164     & 30,811,855       \\
% roadNet-PA       & 1,090,920      & 3,083,796    & 2.8   & 9         &  7,238,920     &  9,931,528       \\
% roadNet-TX       & 1,393,383      & 3,843,320    & 2.7   & 12        &  8,903,897     & 12,264,987       \\
% belgium\_osm     & 1,441,295      & 3,099,940    & 2.1   & 10        &  5,323,073     &  8,408,599       \\
% roadNet-CA       & 1,971,281      & 5,533,214    & 2.8   & 12        & 12,908,450     & 17,743,342       \\
% netherlands\_osm & 2,216,688      & 4,882,476    & 2.2   & 7         &  8,755,758     & 13,626,132       \\ 
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% Для замеров производительности алгоритмов поиска путей с КС ограничениями используется коллекция графовых данных лаборатории языковых инструментов JetBrains Research~\cite{net:cfpq_data}, которая использовалась в ряде работ~\cite{inproceedings:matrix_cfpq, inproceedings:cfpq_matrix_evaluation, inbook:kronecker_cfpq_adbis, inproceedings:cfqp_matrix_with_single_source} для подобных экспериментов. 
% Данная коллекция содержит RDF данные, а также графы программ, полученные из различных модулей ядра Linux (\textit{arch}, \textit{crypto}, \textit{drivers}, \textit{fs}). 
% Информация о графах представлена в таблице~\ref{table:graphs_for_cfpq}. 
% В таблице приведено название графа, количество вершин и ребер, а также количество ребер с метками sco (subClassOf), type, bt (broaderTransitive), которые относятся к RDF графам, а также с метками a (assignment) и d (dereference), которые относятся к графам программ. В верхней секции таблицы расположены RDF графы, а в нижней --- графы программ. 
% Для анализа RDF данных используются same-generations queries $G_1$ (выражение~\ref{eqn:g_1}), $G_2$ (выражение~\ref{eqn:g_2}), а также $G_{geo}$ (выражение~\ref{eqn:geo}), представленная в исследовании Йохема Куиджперса и др.~\cite{article:kuijpers_cfpq_exp_compare} для анализа \textit{geospicies} RDF. 
% Графы программ используются для анализа указателей. 
% Данная проблема может быть сведена к запросам с КС ограничениями, что показано в исследовании Чжэн Синь и др.~\cite{Zheng:2008:DAA:1328897.1328464}. Для этого можно использовать грамматику $G_{ma}$ (выражение~\ref{eqn:ma}), предложенную в исследовании Кай Ван и др.~\cite{10.1145/3093336.3037744}. Черточка в выражении над меткой обозначает обратное отношение или обратное ребро в графе. 

% \begin{align}
% \begin{split}
% \label{eqn:g_1}
% S \to & \overline{\textit{subClassOf}} \ \ S \ \textit{subClassOf} \mid \overline{\textit{type}} \ \ S \ \textit{type}\\   & \mid \overline{\textit{subClassOf}} \ \ \textit{subClassOf} \mid \overline{\textit{type}} \ \textit{type}
% \end{split}
% \end{align}
% \begin{align}
% \begin{split}
% \label{eqn:g_2}
% S \to \overline{\textit{subClassOf}} \ \ S \ \textit{subClassOf} \mid \textit{subClassOf}
% \end{split}
% \end{align}
% \begin{align}
% \begin{split}
% \label{eqn:geo}
% S \to & \textit{broaderTransitive} \ \  S \ \overline{\textit{broaderTransitive}} \\
%       & \mid \textit{broaderTransitive} \ \  \overline{\textit{broaderTransitive}}
% \end{split}
% \end{align}
% \begin{align}
% \begin{split}
% \label{eqn:ma}
% S & \to \overline{d} \ V \ d \\
% V & \to ((S?) \overline{a})^* (S?) (a (S?))^*
% \end{split}
% \end{align}

% \begin{table}
% \begin{center}
% \caption{RDF графы и графы программ для КС запросов}
% \label{table:graphs_for_cfpq}
% \scriptsize
% \rowcolors{2}{black!2}{black!10}
% \scalebox{1.1 }{
% \begin{tabular}{|l|r|r|r|r|r|r|r|}
% \hline
% Граф $\mathcal{G}$ & $|V|$  & $|E|$      & Кол-во $sco$ & Кол-во $type$ & Кол-во $bt$ & Кол-во $a$  & Кол-во $d$ \\
% \hline
% \hline
% go-hierarchy   & 45 007     & 980 218    & 490 109   & 0         &        ---        & ---  & --- \\
% enzyme         & 48 815     & 109 695    & 8 163     & 14 989    &        ---        & ---  & --- \\
% eclass\_514en  & 239 111    & 523 727    & 90 512    & 72 517    &        ---        & ---  & --- \\
% go             & 272 770    & 534 311    & 90 512    & 58 483    &        ---        & ---  & --- \\
% geospecies     & 450 609    & 2 201 532  & 0         & 89 062    &        20 867     & ---  & --- \\
% taxonomy       & 5 728 398  & 14 922 125 & 2 112 637 & 2 508 635 &        ---        & ---  & --- \\
% \hline
% arch           & 3 448 422  & 5 940 484  &      ---     &  ---   &        ---        & 671 295 & 2 298 947 \\
% crypto         & 3 464 970  & 5 976 774  &      ---     &  ---   &        ---        & 678 408 & 2 309 979 \\
% drivers        & 4 273 803  & 7 415 538  &      ---     &  ---   &        ---        & 858 568 & 2 849 201 \\
% fs             & 4 177 416  & 7 218 746  &      ---     &  ---   &        ---        & 824 430 & 2 784 943 \\
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% \subsubsection*{Метрики}

% Для ответа на поставленные исследовательские вопросы в качестве метрик производительности используется время, требуемое для выполнения операции/запроса, а также пиковое количество потребляемой RAM или VRAM (в зависимости от платформы инструмента) в момент вычисления. 
% Показатели времени усреднены по 10 запускам. 
% Отклонение показателей составляет не более 10\% для каждого отдельного эксперимента.
% Предварительно совершался не учитывающийся в замерах запуск, чтобы инициализировать начальное состояние тестируемых библиотек. 
% Показатели потребления RAM получены с помощью дополнительных функций библиотеки С для семейства ОС на базе ядра Linux.  
% Показатели потребления VRAM получены с помощью стандартного инструмента \textit{nvidia-smi}, который с точностью до $1$ миллисекунды позволяет отслеживать количество потребляемой памяти процессом ОС на стороне видеокарты. 

% \subsection{Результаты}


% \textit{В1: Какова производительность отдельных операций реализованной библиотеки примитивов разреженной линейной булевой алгебры на GPGPU по сравнению с существующими аналогами?} 

% Результаты эксперимента по сравнению производительности матричного произведения представлены в таблице~\ref{table:eval_mm_results}.
% Реализованная библиотека cuBool показывает лучшие результаты по сравнению с другими библиотеками. 
% Используемый в реализации алгоритм Nsparse позволяет получить прирост в скорости до 5 раз, а также сократить потребление видеопамяти до 8 раз, что особенно заметно в сравнении с такими библиотеками как CUSP или clSPARSE.

% Результаты эксперимента по сравнению производительности матричного поэлементного сложения представлены в таблице~\ref{table:eval_ma_results}. 
% Библиотека clSPRARSE не реализует данную операцию, поэтому относящаяся к ней колонка с результатами оставлена пустой.
% cuBool демонстрирует хорошую производительность, его показатели времени сравнимы с такими промышленными библиотеками как CUSP или cuSPRASE и отличаются незначительно как в большую, так и меньшую сторону. 
% Однако используемая cuBool операция сложения потребляет значительно меньше видеопамяти во время обработки, что позволяет местами достигать до 3 раз меньших значений в сравнении с CUSP.

% \begin{table}[]
% \begin{center}
% \caption{Матричное умножение (время (t) в миллисекундах, память (m) в мегабайтах, отклонение в пределах 10\%)}
% \label{table:eval_mm_results}
% % \scriptsize
% \rowcolors{3}{black!2}{black!10}
% \scalebox{0.7}{
% \begin{tabular}{| l | r r | r r | r r | r r | r r |}
% \hline
% Матрица $M$       & \multicolumn{2}{c|}{cuBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{cuSPRS} & \multicolumn{2}{c|}{clSPRS} & \multicolumn{2}{c|}{SuiteSprs} \\   
%                   & t    & m   & t     & m    & t      & m   & t     & m    & t     & m   \\
% \hline
% \hline
%  wing             & 1.9  & 93  & 5.2   & 125  & 20.1   & 155 & 4.2   & 105  & 7.9   & 22  \\ % 1.  wing             
%  luxembourg\_osm  & 2.4  & 91  & 3.7   & 111  & 1.7    & 151 & 6.9   & 97   & 3.1   & 169 \\ % 2.  luxembourg\_osm  
%  amazon0312       & 23.2 & 165 & 108.5 & 897  & 412.8  & 301 & 52.2  & 459  & 257.6 & 283 \\ % 3.  amazon0312       
%  amazon-2008      & 33.3 & 225 & 172.0 & 1409 & 184.8  & 407 & 77.4  & 701  & 369.5 & 319 \\ % 4.  amazon-2008      
%  web-Google       & 41.8 & 241 & 246.2 & 1717 & 4761.3 & 439 & 207.5 & 1085 & 673.3 & 318 \\ % 5.  web-Google       
%  roadNet-PA       & 18.1 & 157 & 42.1  & 481  & 37.5   & 247 & 56.6  & 283  & 66.6  & 294 \\ % 6.  roadNet-PA       
%  roadNet-TX       & 22.6 & 167 & 53.1  & 581  & 46.7   & 271 & 70.4  & 329  & 80.7  & 328 \\ % 7.  roadNet-TX       
%  belgium\_osm     & 23.2 & 151 & 32.9  & 397  & 26.7   & 235 & 68.2  & 259  & 56.9  & 302 \\ % 8.  belgium\_osm     
%  roadNet-CA       & 32.0 & 199 & 74.4  & 771  & 65.8   & 325 & 98.2  & 433  & 114.5 & 344 \\ % 9.  roadNet-CA       
%  netherlands\_osm & 35.3 & 191 & 51.0  & 585  & 51.4   & 291 & 102.8 & 361  & 90.9  & 311 \\ % 10. netherlands\_osm  
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% \begin{table}[]
% \begin{center}
% \caption{Поэлементное матричное сложение (время (t) в миллисекундах, память (m) в мегабайтах, отклонение в пределах 10\%)}
% \label{table:eval_ma_results}
% % \scriptsize
% \rowcolors{3}{black!2}{black!10}
% \scalebox{0.7}{
% \begin{tabular}{| l | r r| r r | r r | r r | r r |}
% \hline
% Матрица $M$       & \multicolumn{2}{c|}{cuBool} & \multicolumn{2}{c|}{CUSP} & \multicolumn{2}{c|}{cuSPRS} & \multicolumn{2}{c|}{clSPRS} & \multicolumn{2}{c|}{SuiteSprs} \\   
%                   & t    & m   & t    & m   & t    & m   & t      & m      & t    & m   \\
% \hline
% \hline
%  wing             & 1.1  & 95  & 1.4  & 105 & 2.4  & 163 & ~~---  & ~~---  & 2.3  & 176 \\ % 1.  wing             
%  luxembourg\_osm  & 1.7  & 95  & 1.0  & 97  & 0.8  & 151 & ~~---  & ~~---  & 1.6  & 174 \\ % 2.  luxembourg\_osm  
%  amazon0312       & 11.4 & 221 & 16.2 & 455 & 24.3 & 405 & ~~---  & ~~---  & 37.2 & 297 \\ % 3.  amazon0312       
%  amazon-2008      & 17.5 & 323 & 29.5 & 723 & 27.2 & 595 & ~~---  & ~~---  & 64.8 & 319 \\ % 4.  amazon-2008      
%  web-Google       & 24.8 & 355 & 31.9 & 815 & 89.0 & 659 & ~~---  & ~~---  & 77.2 & 318 \\ % 5.  web-Google       
%  roadNet-PA       & 16.9 & 189 & 11.2 & 329 & 11.6 & 317 & ~~---  & ~~---  & 36.6 & 287 \\ % 6.  roadNet-PA       
%  roadNet-TX       & 19.6 & 209 & 14.5 & 385 & 16.9 & 357 & ~~---  & ~~---  & 45.3 & 319 \\ % 7.  roadNet-TX       
%  belgium\_osm     & 19.5 & 179 & 10.2 & 303 & 10.5 & 297 & ~~---  & ~~---  & 28.5 & 302 \\ % 8.  belgium\_osm     
%  roadNet-CA       & 30.5 & 259 & 19.4 & 513 & 20.2 & 447 & ~~---  & ~~---  & 65.2 & 331 \\ % 9.  roadNet-CA       
%  netherlands\_osm & 30.1 & 233 & 14.8 & 423 & 18.3 & 385 & ~~---  & ~~---  & 50.2 & 311 \\ % 10. netherlands\_osm  
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% \textit{В2: Какова производительность реализованного алгоритма поиска путей через тензорное произведение на GPGPU по сравнению с существующими аналогами, также полагающимися на примитивы линейной алгебры?}

% Для краткости изложения алгоритм на основе тензорного произведения обозначен как Tns, а алгоритм Рустама Азимова --- как Mtx.
% Также используется нижний индекс для обозначения платформы, для которой данный алгоритм реализован.
% Версия на основе \textbf{pycubool} для вычислений на GPU обозначена как \textit{gpu}, а версия на основе \textbf{pygraphblas} для вычислений на CPU  --- как \textit{}{cpu}. Ячейка таблицы помечена надписью $err$, если тестируемый алгоритм завершился аварийно из-за нехватки видеопамяти. 

% Необходимо отметить, что алгоритм на основе тензорного произведения позволяет в результате выполнения получать информацию не только о достижимости вершин, но и о путях, в сравнении с классическим алгоритмом Рустама Азимова.
% Во время работы он поддерживает тот же набор матриц, что и алгоритм Рустама Азимова, а также специальную матрицу с индексом путей, что требует дополнительное время и память на обработку. 
% Поэтому нельзя считать б\'ольшее время обработки/потребление памяти недостатком в дальнейшем сравнении.

% Результаты эксперимента по анализу RDF данных представлены в таблице~\ref{table:eval_rdf_g1_g2_results} и в таблице~\ref{table:eval_rdf_geo_results}. 
% Tns$_{gpu}$ и Mtx$_{gpu}$ демонстрируют хорошую производительность и в целом показывают лучшие временные характеристики и меньший расход память относительно аналогов для CPU-вычислений. 
% Однако, на RDF графах для запросов с $G_1$ и $G_2$ прирост скорости незначительный, 
% так как данные графы имеют относительно небольшой размер.
% Поэтому для подобного рода анализа достаточно использовать версии алгоритмов для вычислений на CPU. 
% Анализ графа \textit{geospecies} с использованием запроса $G_{geo}$ показывает увеличение скорости обработки в 7 раз и снижение потребления памяти на 30\% для Mtx$_{gpu}$. 
% Tns$_{gpu}$ не смог завершиться в данном эксперименте из-за нехватки VRAM.


% \begin{table}[h]
% \begin{center}
% \caption{Анализ RDF данных с использованием запросов $G_1$ и $G_2$ (время (t) в секундах, память (m) в мегабайтах, отклонение в пределах 10\%)}
% \label{table:eval_rdf_g1_g2_results}
% % \scriptsize
% \rowcolors{5}{black!2}{black!10}
% \scalebox{0.67}{
% \begin{tabular}{| l | r r| r r | r r | r r | r r| r r | r r | r r |}
% \hline
%                   & \multicolumn{8}{c|}{G$_1$}                                                         & \multicolumn{8}{c|}{G$_2$}                                                     \\ \cline{2-17}
% Граф $\mathcal{G}$ & \multicolumn{2}{c|}{Tns$_{gpu}$} 
%                                   & \multicolumn{2}{c|}{Tns$_{cpu}$} 
%                                                   & \multicolumn{2}{c|}{Mtx$_{gpu}$} 
%                                                                   & \multicolumn{2}{c|}{Mtx$_{cpu}$} 
%                                                                                                         & \multicolumn{2}{c|}{Tns$_{gpu}$} 
%                                                                                                                         & \multicolumn{2}{c|}{Tns$_{cpu}$} 
%                                                                                                                                       & \multicolumn{2}{c|}{Mtx$_{gpu}$} 
%                                                                                                                                                       & \multicolumn{2}{c|}{Mtx$_{cpu}$} \\   
%                   & t     & m     & t     & m    & t      & m     & t     & m                          & t     & m     & t    & m    & t      & m     & t     & m                        \\ 
% \hline
% \hline
%   go-hierarchy    & 0.15  & 315   & 0.17  & 265  & 0.11   & 208   & 0.08  & 254                        & 0.27  & 484   & 0.24 & 252  & 0.06   & 6    & 0.09 & 255                       \\
%   enzyme          & 0.02  & 9     & 0.04  & 137  & 0.01   & $<$1  & 0.01  & 181                        & 0.01  & 4     & 0.02 & 132  & 0.01   & $<$1 & 0.01 & 181                       \\
%   eclass\_514en   & 0.10  & 57    & 0.24  & 205  & 0.04   & 14    & 0.07  & 180                        & 0.09  & 36    & 0.27 & 193  & 0.02   & 2    & 0.06 & 181                       \\
%   go              & 1.67  & 176   & 1.58  & 282  & 0.43   & 68    & 1.00  & 244                        & 0.82  & 119   & 1.27 & 243  & 0.18   & 12   & 0.94 & 246                       \\
%   taxonomy        & 2.21  & 1266  & 4.42  & 2018 & 0.71   & 364   & 1.13  & 968                        & 0.90  & 969   & 3.56 & 1776 & 0.24   & 91   & 0.72 & 1175                      \\
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% \begin{table}[h]
% \begin{center}
% \caption{Анализ RDF данных с использованием запроса $G_{geo}$ (время (t) в секундах, память (m) в мегабайтах, отклонение в пределах 10\%)}
% \label{table:eval_rdf_geo_results}
% % \scriptsize
% \rowcolors{3}{black!2}{black!10}
% \scalebox{0.8}{
% \begin{tabular}{| l | r r| r r | r r | r r |}
% \hline
% Граф $\mathcal{G}$& \multicolumn{2}{c|}{Tns$_{gpu}$} & \multicolumn{2}{c|}{Tns$_{cpu}$} & \multicolumn{2}{c|}{Mtx$_{gpu}$} & \multicolumn{2}{c|}{Mtx$_{cpu}$} \\   
%                   & t    & m   & t    & m   & t    & m   & t      & m     \\ 
% \hline
% \hline
%   geospecies     & $err$  & $err$    & 26.32 & 19537  & 1.17 & 5272 & 7.48 & 7645 \\
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}

% Результаты эксперимента по анализу указателей на графах программ представлены в таблице~\ref{table:eval_mem_alias_results}.
% Tns$_{gpu}$ и Mtx$_{gpu}$ также как и в предыдущем эксперименте демонстрируют лучшую производительность относительно CPU-аналогов. Tns$_{gpu}$ показывает ускорение до 6 раз и до 15 раз меньшее потребление памяти. 
% Однако данная реализация страдает из-за нехватки VRAM в анализе графа \textit{drivers}.
% Mtx$_{gpu}$ демонстрирует ускорение до 4 раз и до 6 раз меньшее потребление памяти. 
% Из-за меньшего потребления памяти в целом данный алгоритм успешно отработал во всех экспериментах без проблем, связанных с нехваткой VRAM.

% Результаты экспериментального исследования в целом позволяют заключить, 
% что специализация операций в рамках реализованной библиотеки cuBool демонстрирует лучшую производительность 
% (меньше потребление памяти и сравнимое или меньше время выполнения операций) среди известных на текущий момент аналогов. 
% Реализация алгоритма поиска путей с КС ограничениями через тензорное произведение с использованием cuBool для GPU-вычислений позволяет добиться значительного прироста в производительность в сравнении с CPU-версией, 
% что делает ее более применимой для анализа реальных данных. 

% \begin{table}[h]
% \begin{center}
% \caption{Анализ указателей с использованием запроса $G_{ma}$ (время (t) в секундах, память (m) в мегабайтах, отклонение в пределах 10\%)}
% \label{table:eval_mem_alias_results}
% % \scriptsize
% \rowcolors{3}{black!2}{black!10}
% \scalebox{0.8}{
% \begin{tabular}{| l | r r| r r | r r | r r |}
% \hline
% Граф $\mathcal{G}$& \multicolumn{2}{c|}{Tns$_{gpu}$} & \multicolumn{2}{c|}{Tns$_{cpu}$} & \multicolumn{2}{c|}{Mtx$_{gpu}$} & \multicolumn{2}{c|}{Mtx$_{cpu}$} \\   
%                   & t    & m   & t    & m   & t    & m   & t      & m     \\ 
% \hline
% \hline
%   arch           & 57.22 & 1928  & 262.45  & 6718  & 27.90 & 588   & 83.75  & 1842 \\
%   crypto         & 57.43 & 1966  & 257.52  & 6720  & 28.10 & 596   & 84.83  & 1842 \\
%   drivers        & $err$ & $err$ & 1309.57 & 46941 & 62.49 & 3999  & 269.93 & 5750 \\
%   fs             & 83.86 & 3166  & 470.49  & 46941 & 47.67 & 932   & 165.09 & 5750 \\
% \hline
% \end{tabular}
% }
% \end{center}
% \end{table}
